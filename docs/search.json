[
  {
    "objectID": "posts/reproducibilidad.html",
    "href": "posts/reproducibilidad.html",
    "title": "Reproducibilidad: por qué importa y qué tiene que ver con programar bien",
    "section": "",
    "text": "En muchas áreas de investigación, los resultados no se producen de una sola vez. Se construyen a partir de datos, decisiones analíticas, ajustes, correcciones y vueltas atrás. En ese proceso, una pregunta aparece tarde o temprano: ¿otra persona podría obtener los mismos resultados siguiendo los mismos pasos? A esa posibilidad se la suele llamar reproducibilidad.\nLa reproducibilidad se refiere a la capacidad de repetir un análisis y llegar a los mismos resultados usando los mismos datos y los mismos procedimientos. No implica que los resultados sean universales ni definitivos, sino que el camino que llevó a ellos sea claro y verificable. En términos prácticos, un análisis reproducible permite entender qué se hizo, cómo se hizo y en qué orden.\nLa falta de reproducibilidad rara vez se debe a mala intención (aunque a veces ocurre). Más bien suele estar asociada a prácticas habituales pero poco sistemáticas: archivos de datos modificados sin registro, análisis hechos parcialmente en la consola, pasos intermedios que no se guardan, resultados copiados y pegados en documentos finales. Con el tiempo, incluso quien realizó el análisis puede perder la capacidad de reconstruirlo.\n\n\n\nCuando buscamos al culpable de que nuestro código ya no funcione tan solo unos meses después de haberlo escrito.\n\n\nEn este punto, la programación cumple un rol central. Trabajar con código permite dejar registro explícito de cada decisión. Un script puede cómo se cargaron los datos, qué transformaciones se aplicaron, qué modelos se ajustaron y cómo se produjeron los resultados, tanto tablas como gráficos. Ese registro no depende de la memoria ni de explicaciones posteriores. Está escrito y puede leerse, ya sea en texto plano usando un archivo RMarkdown o Quarto, o en los comentarios del propio código.\nLas buenas prácticas de programación refuerzan esta lógica. Escribir código en scripts en lugar de hacerlo solo en la consola permite conservar el proceso completo. Usar nombres claros para objetos y funciones facilita la lectura. Agregar comentarios ayuda a entender por qué se tomó cierta decisión y no otra. Organizar el trabajo en proyectos mantiene juntos los datos, el código y los resultados. Todas estas prácticas apuntan a lo mismo: que el análisis pueda ser retomado y entendido.\nLa reproducibilidad también se beneficia de la separación entre datos crudos y datos procesados. Mantener una versión original de los datos y realizar todas las transformaciones mediante código evita errores difíciles de detectar. Si algo cambia en los datos de entrada (por ejemplo, si agregaste sujetos a tu toma de datos), el análisis puede volver a ejecutarse sin necesidad de rehacer pasos de forma manual.\nOtro aspecto clave es la automatización. Cuando los resultados se generan a partir del código, no hace falta copiar valores de un lado a otro. Gráficos, tablas y estadísticas se producen directamente desde los scripts. Esto reduce errores y asegura que los resultados estén alineados con los datos y las decisiones actuales del análisis.\nHerramientas como RStudio facilitan este enfoque. El trabajo con proyectos, el uso de scripts y la posibilidad de integrar código y texto en documentos reproducibles como RMarkdown permiten construir análisis que se ejecutan de principio a fin. El resultado es un trabajo más transparente, tanto para quien lo realiza como para quien lo lee.\nLa reproducibilidad no es un objetivo abstracto ni una exigencia externa. Tiene efectos muy concretos en el trabajo cotidiano. Ahorra tiempo cuando hay que corregir algo, permite retomar análisis después de semanas o meses y facilita el intercambio con otras personas. Incluso cuando el análisis no se va a compartir públicamente, trabajar de forma reproducible mejora la calidad del proceso.\nProgramar bien no garantiza por sí solo la reproducibilidad, pero crea las condiciones para que sea posible. Escribir código legible, ordenado y documentado convierte al análisis en un objeto que puede revisarse, discutirse y mejorarse. En ese sentido, las buenas prácticas de programación forman parte del trabajo científico tanto como la formulación de preguntas o la interpretación de resultados.\nEn los próximos textos de esta serie, vamos a seguir profundizando en herramientas concretas que ayudan a sostener esta forma de trabajar, desde la organización del código hasta el uso de control de versiones."
  },
  {
    "objectID": "posts/r-humanidades-aprender.html",
    "href": "posts/r-humanidades-aprender.html",
    "title": "R para humanidades: ¿Por qué aprender a programar?",
    "section": "",
    "text": "Aprender a programar suele presentarse como una habilidad técnica, asociada un mercado laboral centrado en lo tecnológico. Para quienes venimos de las ciencias sociales y humanas, ese mundo nos puede resultar ajeno. Nuestro trabajo cotidiano tiene otra materialidad (¿textos?) y está atravesado por preguntas sobre el lenguaje, la interpretación, la construcción de categorías y la producción situada de conocimiento. Sin embargo, cada vez más surgen herramientas tecnológicas que permiten imbricar ambos mundos y cada vez más hay personas del mundo de la lingüística, la sociología o las ciencias políticas trabajando con código y ciencias de datos.\nNos solemos detener a pensar qué nos aporta la programación a quienes trabajamos en estas áreas, pero, ¿qué podemos aportar nosotros y nosotras a ese mundo? ¿Qué nuevas miradas podemos brindar sobre la tecnología? Hay una que nos parece central, que hemos mencionado varias veces porque está en el fondo de nuestra experiencia: programar es escribir. Más allá de las obvias asociaciones entre un “lenguaje natural” y un “lenguaje de programación”, creemos que hay fundamentalmente una dimensión textual que comparten tanto los textos como los scripts. En ese marco, proponemos ver a la programación no tanto como una destreza instrumental, sino más bien como una práctica de escritura y de análisis que dialoga con preocupaciones ya conocidas.\nProgramar implica escribir instrucciones en un lenguaje formal, pero también leerlas, interpretarlas y revisarlas. Un script en R no es solo una secuencia de comandos que “funciona” o “no funciona”: es un texto que condensa decisiones analíticas, supuestos teóricos y recortes metodológicos. ¿Por dónde empezamos? ¿Cuánto nos detenemos en un análisis descriptivo o cuánto en un análisis inferencial? ¿Escribimos en soledad o esperamos que alguien más nos lea? ¿Comentamos nuestro texto?\nDel mismo modo que analizamos un texto académico preguntándonos qué conceptos usa, qué deja afuera o cómo organiza su argumento, el código también puede leerse críticamente. Aprender a programar en R, entonces, abre la posibilidad de pensar con datos de una manera explícita y revisable.\nR es especialmente interesante para este cruce porque nació y se desarrolló en el ámbito académico. Su uso extendido en estadística, lingüística, sociología, psicología y ciencias de la educación no es casual. La lógica del lenguaje favorece un trabajo exploratorio y reflexivo con los datos, donde cada paso del análisis puede quedar registrado. Además, su ecosistema de paquetes refleja debates y tradiciones disciplinares concretas, que se materializan en funciones, argumentos y estructuras de datos. Paradójicamente, muchas personas ven el debate R vs Python como un debate de academia vs industria (mayoritariamente por quienes vienen de la industria y tienen sesgos negativos hacia el trabajo académico).\nAlgo de esto se ve en los materiales de aprendizaje de los cursos: la amplia mayoría se enfocan en instrucciones sobre cómo realizar una determinada tarea, pero pocas veces hay explicaciones sobre el funcionamiento intrínseco del lenguaje. De hecho, pocas veces se resalta el aspecto lingüístico de un lenguaje de programación, a pesar de heredar atributos como la sintaxis o la semántica. Quienes venimos de la lingüística y tenemos incorporada la mirada sobre los aspectos formales o combinatorios de las estructuras tenemos una ventaja que no suele mencionarse. Más bien, lo contrario: quienes vienen de las ciencias sociales y humanas suelen sentir que su forma de pensar es distinta a la necesaria para adentrarse al mundo de la tecnología (sobre eso charlamos en el #LatinR2024).\nDesde nuestra perspectiva, aprender a programar no significa abandonar prácticas propias de otras áreas. Al contrario, implica extenderlas a un nuevo tipo de texto. El código se convierte en un espacio donde se articulan teoría, método y datos. Herramientas como RStudio, y prácticas como el uso de scripts reproducibles o documentos en R Markdown, refuerzan esta idea al integrar código, texto y resultados en un mismo soporte.\nEn el cierre de esta reflexión, vale insistir en una idea central: la programación es una práctica situada. Se aprende en contextos específicos, para responder a preguntas concretas, con tradiciones disciplinares determinadas. Aprender R desde las humanidades y las ciencias sociales no implica adoptar sin más un lenguaje ajeno, sino apropiarse de él, leerlo críticamente y usarlo para pensar problemas propios. Programar, en este sentido, es otra forma de escribir, analizar y producir conocimiento."
  },
  {
    "objectID": "posts/proyectos-rstudio.html",
    "href": "posts/proyectos-rstudio.html",
    "title": "Trabajar con proyectos en RStudio: ordenar el trabajo desde el inicio",
    "section": "",
    "text": "Cuando se empieza a usar R, es común trabajar con archivos sueltos: un script por acá, un archivo de datos por allá, resultados guardados en el escritorio o en carpetas poco claras. Ese modo de trabajo suele funcionar al principio, pero se vuelve frágil cuando el análisis crece, cuando pasa el tiempo o cuando otra persona necesita entender qué se hizo (¡o vos en el futuro!). En ese punto aparece una herramienta clave de RStudio: los proyectos.\nUn proyecto en RStudio es una forma de organizar el trabajo en una carpeta principal. Todo lo que pertenece a un análisis o proyecto determinado vive dentro de ese espacio: scripts, datos, gráficos, tablas y documentos. Al abrir un proyecto, RStudio sabe dónde está parado y trabaja siempre desde ese lugar. Esto evita uno de los problemas más frecuentes al empezar: los errores de rutas absolutas o relativas, y archivos que “no se encuentran”.\nDesde un punto de vista conceptual, trabajar con proyectos ayuda a hacer explícita la estructura del trabajo. El análisis deja de ser una sucesión de comandos dispersos y pasa a tener un marco claro. Cada archivo cumple una función y su ubicación tiene sentido. Además, el proyecto guarda información sobre el entorno de trabajo, lo que hace más fácil retomar el análisis después de un tiempo sin tener que reconstruir todo desde cero.\nLos proyectos también favorecen la reproducibilidad. Si todo está dentro de una misma carpeta, es más sencillo mover el trabajo a otra computadora o compartirlo, por ejemplo a través de un repositorio de Github. No hace falta reescribir rutas absolutas ni ajustar configuraciones cada vez. RStudio se encarga de abrir el proyecto y dejar todo listo para continuar.\n\nCómo crear un proyecto en RStudio paso a paso\n\nAbrí RStudio.\nEn el menú superior, hacé clic en File y luego en New Project….\nRStudio va a ofrecer tres opciones. Para empezar, la más simple es New Directory.\nElegí New Project.\nIndicá el nombre del proyecto y la ubicación donde querés que se cree la carpeta.\nHacé clic en Create Project.\n\nRStudio va a crear una carpeta con ese nombre y abrir automáticamente el proyecto. A partir de ese momento, cada vez que abras ese archivo de proyecto, identificado por la extensión .Rproj, RStudio va a trabajar desde esa carpeta. Lo vas a ver en la esquina superior derecha, al lado de un cubo celeste con una “R”:\n\n\n\nQué cambia al trabajar dentro de un proyecto\nUna vez que el proyecto está creado, conviene adoptar algunas prácticas simples. Guardar los scripts dentro de la carpeta del proyecto, por ejemplo en una subcarpeta llamada scripts. Colocar los datos en otra carpeta, como data. Guardar gráficos o tablas en carpetas específicas. Esta organización no es obligatoria, pero ayuda a que el trabajo sea más legible.\nOtro cambio importante es el uso de rutas relativas. Dentro de un proyecto, cuando se hace referencia a un archivo, se lo nombra en relación con la carpeta del proyecto. Por ejemplo, data/encuesta.csv. Esto funciona siempre que el proyecto esté abierto y evita errores cuando el análisis se mueve de lugar.\nRStudio también muestra el nombre del proyecto activo en la esquina superior derecha. Ese detalle visual sirve como recordatorio constante de en qué contexto se está trabajando. Abrir un script sin abrir el proyecto puede generar confusión, por lo que conviene acostumbrarse a iniciar el trabajo siempre desde el archivo .Rproj.\nPor último: una recomendación personal. Antes de terminar de trabajar o de cerrar el archivo, probá reiniciar la sesión de RStudio (en la barra superior, Session y después Restart R), y probá ejecutar todo el código desde cero. Si todo sale bien, entonces el código está limpio y listo para ser guardado. Pero si modificaste algo (por ejemplo en la consola) que rompió la continuidad del código, va a saltar un error. Y creeme que es mejor corregirlo en el momento que al día siguiente (o meses o años después…).\n\n\nProyectos como hábito de trabajo\nTrabajar con proyectos no requiere conocimientos avanzados ni cambia la forma de escribir código. Cambia, sobre todo, la forma de organizarlo. Incorporar este hábito desde el inicio ahorra tiempo, reduce errores y hace que el análisis sea más fácil de entender, incluso para quien lo hizo.\nEn el próximo post de esta serie vamos a dar un paso más y explicar cómo conectar un proyecto de RStudio con un sistema de control de versiones. Eso permite llevar un registro de cambios, volver a estados anteriores del trabajo y colaborar de manera más ordenada."
  },
  {
    "objectID": "posts/libros-aprender-ciencia-datos.html",
    "href": "posts/libros-aprender-ciencia-datos.html",
    "title": "6 libros imprescindibles para aprender Ciencia de Datos",
    "section": "",
    "text": "Profundizar en ciencia de datos va más allá de aprender sintaxis o ejecutar comandos. Leer libros que articulan conceptos, técnicas y reflexiones ayuda a entender el campo en conjunto. Afortunadamente, existen textos accesibles de forma gratuita en la web que cubren desde fundamentos hasta aplicaciones concretas. A continuación presento cinco libros recomendados, de acceso libre. Algunos están en inglés, otros en español.\n\n1. R for Data Science (Hadley Wickham, Garrett Grolemund y Mine Çetinkaya-Rundel)\nEste libro es el fundamento absoluto sobre la programación en R en el mundo de la ciencia de datos. Abarca temas como la limpieza y la visualización de datos, entre otros temas. Está pensado para quien recién empieza, pero con un nivel de detalle que permite seguir aprendiendo de forma continua. Tiene su versión en español aquí.\n\n\n2. Telling Stories with Data (Rohan Alexander)\nEnfocado en la comunicación estadística y la narrativa de los análisis, este libro cubre desde la recopilación y limpieza de datos hasta la presentación de resultados. Incluye ejemplos de código y actividades que refuerzan la comprensión de cada técnica. Su enfoque en cómo traducir datos en conclusiones claras lo hace especialmente útil para quienes trabajan con análisis interpretativos.\n\n\n3. Libro Vivo de Ciencia de Datos (Pablo Casas)\nEste libro en español presenta una introducción intuitiva a la ciencia de datos y al machine learning, con un enfoque didáctico. Propone una visión práctica de cómo pensar y trabajar con datos desde niveles iniciales.\n\n\n4. Deep R Programming (Marek Gagolewski)\nAunque más técnico, este recurso gratuito ofrece una introducción profunda al lenguaje R desde la perspectiva de la ciencia de datos. El libro cubre transformaciones de datos, cálculo numérico, programación funcional y estructuras avanzadas, con ejemplos y ejercicios prácticos.\n\n\n5. OpenIntro Statistics (David Diez, Christopher Barr y Mine Çetinkaya-Rundel)\nAunque este texto es un libro de estadística, es una lectura esencial para ciencia de datos. La estadística es un pilar del análisis de datos, y este libro acompaña al lector desde los conceptos básicos hasta técnicas aplicadas.\n\n\n6. Learning Statistics with R (Danielle Navarro)\nEste libro en inglés recopila los materiales de un curso de introducción a la estadística que la autora dio en la Universidad de Adelaide, con ejemplos en R. Condensa no solamente la teoría sino también la práctica para llevar adelante un análisis de datos real e informado. Además, Danielle es una persona muy activa en la comunidad de R y sus aportes son realmente fundamentales.\n\n\nCómo usar estos libros en tu aprendizaje\nEstos textos sirven distintos propósitos: algunos introducen conceptos generales, otros profundizan en herramientas específicas y otros integran programación y análisis. Una estrategia de lectura efectiva puede combinar un libro más conceptual con materiales prácticos que incluyan ejercicios de código y casos reales.\nSi estás comenzando, puede ser útil empezar por capítulos introductorios (por ejemplo, fundamentos de ciencia de datos y comunicación de resultados) antes de avanzar hacia textos más técnicos o centrados en lenguajes específicos como R."
  },
  {
    "objectID": "posts/instalar-r-rstudio.html",
    "href": "posts/instalar-r-rstudio.html",
    "title": "Empezar con R: instalación y primeros pasos",
    "section": "",
    "text": "Empezar con R suele generar dudas muy concretas. Qué hay que instalar, en qué orden, para qué sirve cada cosa. Antes de escribir una sola línea de código, conviene aclarar este punto, porque R funciona a partir de varias piezas que se combinan entre sí. La buena noticia es que el proceso de instalación es sencillo y solo hay que hacerlo una vez.\nEl primer paso es instalar R. R es el lenguaje de programación propiamente dicho. Para hacerlo, hay que ir al sitio oficial del proyecto CRAN, y elegir el archivo instalador que corresponda a nuestro sistema operativo (Windows, macOS o Linux). Al hacer clic, accedemos a las instrucciones específicas para cada caso.\n\n\n\nInstalar R desde CRAN\n\n\nTécnicamente podríamos usar R directamente desde ese software que acabamos de instalar, en Windows y en macOS. Sin embargo, no es una interfaz gráfica muy amigable, por lo que la mayoría de las personas usa otros entornos como RStudio, VSCode o Positron. Si recién estamos empezando, es preferible usar RStudio, porque la mayoría de los tutoriales van a mostrar imágenes de ese entorno.\nComo mencionamos en un post anterior, RStudio es un programa independiente que se instala por separado. Es una interfaz gráfica (técnicamente, un entorno de desarrollo integrado) que facilita la interacción entre el usuario y el lenguaje de programación R. Para instalarlo, hay que ir al sitio de RStudio y descargar la versión gratuita. Como se ve en la imagen, también podemos instalar R desde aquí, pero si ya lo instalamos desde CRAN no es necesario volver a instalarlo.\n\n\n\nInstalar RStudio.\n\n\nAl abrir RStudio por primera vez, este detecta automáticamente la instalación de R y queda listo para usar. A partir de ese momento, RStudio se convierte en el espacio principal de trabajo.\nCon R y RStudio instalados, ya es posible escribir y ejecutar código. El siguiente paso habitual es instalar paquetes, que son agregados que amplían las capacidades de R. Uno de los más usados es el Tidyverse, un conjunto de paquetes pensados para trabajar con datos de manera ordenada y legible (podés leer más sobre qué son los paquetes acá).\nInstalar un paquete en R se hace escribiendo una instrucción en la consola. En el caso del Tidyverse, el comando es:\ninstall.packages(\"tidyverse\")\nUna vez que escribimos el código, debemos ejecutarlo (control+Enter o el ícono de “Run”). Este paso requiere conexión a internet y puede demorar unos minutos, porque el Tidyverse incluye varios paquetes. Van a aparecer muchos mensajes de colores en la consola: eso es normal (a menos que aparezca algo que diga “Warning” o “Error”). La instalación se hace una sola vez. Una vez instalado, para usarlo en una sesión de trabajo hay que cargarlo con:\nlibrary(tidyverse)\nEsta diferencia entre instalar y cargar suele confundir al principio. Instalar descarga el paquete en la computadora. Cargar lo pone a disposición en la sesión actual de R. Cada vez que se inicia una sesión nueva y se quiere usar el Tidyverse, hay que volver a ejecutar library(tidyverse).\nDespués de cargarlo, R muestra algunos mensajes en la consola indicando qué paquetes se activaron. A partir de ese momento, funciones como ggplot, mutate o filter quedan disponibles. No hace falta entenderlas todas de inmediato. Lo importante es saber que forman parte de un mismo ecosistema y que comparten una lógica común.\nUn punto práctico para quienes empiezan es verificar que todo esté funcionando. Por ejemplo, escribir una línea simple como:\nggplot(mtcars, aes(x = mpg, y = wt)) + geom_point()\nSi aparece un gráfico, la instalación fue exitosa. No importa si todavía no se entiende el código. Eso se irá trabajando más adelante.\nInstalar R, RStudio y el Tidyverse marca el inicio del trabajo. A partir de ahí, aprender R implica familiarizarse con el entorno, con la escritura de scripts y con la lectura del código. Tener estas herramientas bien instaladas y funcionando evita muchos problemas innecesarios y permite concentrarse en lo más importante: entender qué hace el código y cómo usarlo para analizar datos.\nEn los próximos posts de esta serie vamos a ir desarmando estas piezas con más detalle, para que el paso inicial se transforme en una base sólida de trabajo."
  },
  {
    "objectID": "posts/consola-script-escribir-codigo.html",
    "href": "posts/consola-script-escribir-codigo.html",
    "title": "Consola y script: dos formas de escribir código en R",
    "section": "",
    "text": "Cuando se abre R o RStudio por primera vez, la consola suele ser el punto de partida. Es la ventana donde aparece el símbolo &gt; y donde se pueden escribir instrucciones directamente. Se escribe una línea de código, se presiona Enter y R responde. Esa respuesta puede ser un número, una tabla, un mensaje o un gráfico. La consola sirve, básicamente, para decirle a R qué hacer y ver el resultado en el momento.\n\nLa consola es útil para acciones rápidas. Por ejemplo, calcular un promedio, ver el contenido de un objeto o probar si una función hace lo que esperamos. También es común usarla para pequeños ensayos mientras se aprende. El problema es que lo que se escribe en la consola no queda guardado de forma ordenada. Si se cierra R o se reinicia la sesión, ese recorrido se pierde. Incluso con la sesión abierta, revisar qué se hizo hace un rato puede resultar confuso.\nEl script cumple otra función. Un script es un archivo donde se escribe código para guardarlo. En RStudio suele tener extensión .R y se abre en el panel del editor (pueden ir a File, New File, R Script o hacer click en el ícono con una cruz verde). Allí se pueden escribir muchas líneas de código, agregar comentarios y organizar el análisis paso a paso. Escribir en un script no ejecuta el código automáticamente. Cada línea o bloque se corre solo cuando se lo indica, ya sea con el botón que dice “Run”, o con control+Enter.\n\nEsta diferencia es importante. El script permite separar dos momentos: escribir y ejecutar. Primero se escribe el código con calma. Después se decide qué ejecutar y cuándo. Esto hace que el trabajo sea más ordenado y más fácil de retomar. Si se vuelve a abrir el archivo días o semanas después, el código sigue ahí, en el orden en que fue pensado.\nUn uso muy habitual es combinar ambos espacios. La consola se usa para probar algo rápido. Si ese código resulta útil, se copia o se escribe directamente en el script. De ese modo, el script va quedando como el registro principal del trabajo, mientras que la consola funciona como un espacio de prueba.\nRStudio facilita esta forma de trabajar. Desde el script se puede ejecutar el código y el resultado aparece en la consola, pero el código quedará guardado en el archivo del script. Esta dinámica es especialmente útil cuando el análisis tiene varios pasos o cuando se quiere compartir el trabajo con otras personas.\nEn términos prácticos, una buena regla inicial es la siguiente: la consola sirve para probar y explorar; el script sirve para guardar y organizar. No hace falta elegir uno u otro de manera excluyente. Lo importante es entender qué aporta cada espacio y usarlo de forma consciente.\nAprender a escribir en scripts desde el principio ahorra tiempo más adelante. Permite corregir errores con facilidad, repetir análisis sin empezar de cero y entender mejor qué se hizo en cada etapa. Para quienes recién empiezan, esta diferencia suele marcar un antes y un después en la forma de trabajar con R."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Atelier de código",
    "section": "",
    "text": "Un espacio dedicado al aprendizaje de la ciencia de datos, con foco en investigación, docencia y prácticas reproducibles."
  },
  {
    "objectID": "index.html#qué-vas-a-encontrar-acá",
    "href": "index.html#qué-vas-a-encontrar-acá",
    "title": "Atelier de código",
    "section": "Qué vas a encontrar acá",
    "text": "Qué vas a encontrar acá\n\nMateriales sobre R y análisis de datos\nProyectos abiertos y documentación\nTutorías y acompañamiento\nAnálisis de datos"
  },
  {
    "objectID": "en/posts/r-programming-language.html",
    "href": "en/posts/r-programming-language.html",
    "title": "R: A Language Born to Think with Data",
    "section": "",
    "text": "When we, from the social sciences and humanities, first approach a programming language, an ambiguous feeling often arises: curiosity, interest, and, at the same time, a certain caution. Programming is frequently associated with a technical practice, distant from reading, discursive analysis, or theoretical reflection. However, we can choose a different entry point to learn R. Its history, its uses, and the community that sustains it make it a language particularly close to an analytical perspective on data and on the conditions of knowledge production.\nR originated in the field of academic statistics. In the early 1990s, Ross Ihaka and Robert Gentleman, statisticians at the University of Auckland, developed R as a free re-implementation of the S language, used since the 1970s in statistical research. From that initial moment, R was conceived as a tool for exploring data, testing models, and supporting scientific research processes. This origin helps to understand many of its current characteristics and also the practices that have consolidated around its use.\nOne of R’s distinctive features is its orientation towards interactive analysis. The code executes progressively and allows for exploratory work with data: trying an operation, observing the result, adjusting the instruction, and re-evaluating. For those accustomed to building analyses iteratively, based on provisional hypotheses and constant reformulations, this mode of work is particularly familiar. Programming in R usually involves sustaining a process of controlled exploration, rather than following a completely predefined path.\nFrom a technical point of view, R relies heavily on the use of functions. Most operations are performed by applying functions to objects (in fact, R is an object-oriented language, just like Python). A function can be understood as a formalized operation that receives one or more arguments, executes a series of internal steps, and returns a result. Calculating an average, transforming a variable, fitting a model, or producing a graph are examples of tasks performed using functions. Reading code in R involves identifying which functions appear, what arguments they receive, and what type of object they generate as output.\nThis emphasis on functions favors a careful reading of code as if it were a text. Each function call presents a relatively stable structure: a name, parentheses, and arguments that can be explicitly named or implicitly defined by default values. For those with experience in text analysis, this syntax can be approached as a system of markers that guides interpretation. Understanding why a function produces a certain result often requires pausing on these details and on the assumptions that the function incorporates.\nOver time, the uses of R expanded considerably. Currently, it is used for statistical analysis, modeling, data visualization, text analysis, social network studies, working with spatial data, and experiments in psychology and linguistics, among many other fields. This expansion is largely explained by the package system. A package is an organized collection of functions, data, and documentation that extends the language’s capabilities. R thus functions as a constantly growing environment, fed by contributions from different academic communities. For the social sciences and humanities, this feature is particularly relevant. Many of the tools available in R were developed by researchers working on problems similar to ours. Packages oriented towards the analysis of surveys, texts, linguistic corpora, or longitudinal data incorporate specific theoretical and methodological decisions. By reading the code that uses these packages, one also accesses these decisions: how a unit of analysis is defined, which operations are considered relevant, what assumptions are adopted about the data.\nIn this sense, R can be thought of as a language in which particular ways of thinking and researching are inscribed. The existence of object classes, the representation of models as examinable objects, or the construction of layered graphics organize the relationship between the analyst and the analyzed phenomenon. Learning R implies learning to recognize and work with these mediations.\nFor this reason, in a series aimed at those beginning programming from the social sciences and humanities, it is productive to present R as a language with a history, conventions, and communities of use. Reading code in R, even when it initially takes time and effort, is part of a technical literacy that dialogues with habitual practices of reading and interpretation.\nIn the next texts in this series, we will introduce concrete code snippets. The goal will be to learn to read them, decompose them, and understand what they are doing and what they are saying. Programming in R, from within our disciplines, implies incorporating a new form of writing and of situated knowledge production."
  },
  {
    "objectID": "en/posts/r-base-tidyverse.html",
    "href": "en/posts/r-base-tidyverse.html",
    "title": "R base, packages, and Tidyverse: what we talk about when we use R",
    "section": "",
    "text": "When we start working with R, one of the first expressions that appears is “R base.” No, just kidding: when we start working with R, we have no idea what we’re doing. We copy code from the courses we’re taking or from the books or tutorials we’re following. It’s possible that these materials contain information about the source of those functions, but as learners, our working memory is a bit saturated, and we’ve probably not paid attention to it.\nAs we incorporate concepts and automate our workflow, we can start paying attention to the theory. And we see these concepts emerge: R base, packages, libraries, Tidyverse. These words circulate naturally in tutorials, classes, and forums, although their meaning and how they relate to each other are not always explicitly stated. However, understanding this architecture is key to being able to read code with greater autonomy and to make informed decisions about how to work with data.\nR base refers to the set of functionalities included when R is installed. It includes the language itself, a wide range of fundamental functions, and some basic packages that are loaded automatically. Arithmetic operations, object creation, basic handling of vectors and data frames, functions like mean(), sum(), plot(), or summary() are part of this core. R base defines the minimal grammar of the language and establishes the rules that allow everything else to function.\nWorking solely with R base is possible, and in fact, for many years, it was the standard way to use R. However, that core is designed to be extended. R was designed from the beginning as a language1, capable of incorporating new functionalities without modifying its central structure. This extensibility is materialized through packages.\nA package is an organized collection of functions, data, and documentation that can be downloaded and incorporated into an R session. Each package addresses a specific need: particular statistical analysis, visualization, text manipulation, survey work, advanced models, or specific data formats. Technically, installing a package means downloading it to your computer; using it means loading it into the active session. Conceptually, using a package implies adopting a particular way of solving analytical problems. There are packages of all types and colors: some focus on functions, others on data. Given that many different packages perform the same actions, there has recently been much emphasis on the importance of citing packages used in data analysis, which has led to the emergence, not without some irony, of packages that facilitate package citation.\nPackages can be thought of as crystallizations of research practices. Whoever develops a package makes decisions about which operations to facilitate, how to name them, which data structures to prioritize, and which assumptions to take for granted. When we use a function from a package, we are not only reusing code but also incorporating a certain way of thinking about analysis. While it is difficult to know a package thoroughly from which we are taking a function, it is always good practice to read its documentation.\nAt this point, another source of confusion often appears: the term “library.” In R, “library” is used to refer to the location where packages are installed on the system, and also, by extension, to the act of loading them using the library() function. In everyday practice, speaking of packages and libraries is often interchangeable, although from a technical standpoint, they are not exactly the same. The important thing is to understand that R base is extended through packages that are loaded according to the needs of the analysis.\nWithin this universe of packages, there is one that occupies a particular place: the Tidyverse. The Tidyverse is not a single package, but a collection of packages designed to work coherently with each other. It includes widely used tools for data manipulation, visualization, and file import, such as dplyr, ggplot2, tidyr, readr, and stringr, among others. All share a common philosophy and a relatively consistent syntax, found in the book R for Data Science by Hadley Wickham and Garrett Grolemund.\nThe central proposal of the Tidyverse is to organize data work based on clear principles. One of the best known is the concept of “tidy data,” where each variable occupies a column, each observation a row, and each type of analytical unit a table.\nThis principle, which may seem purely technical, has important analytical implications because it forces one to explicitly state what is considered a variable, what counts as an observation, and how data is structured. This can change not only between datasets but also between analyses and even between functions. For example, a function that performs a statistical analysis comparing groups might take the grouping variable from a single column or might require each group to have its own column.\nAnother distinctive feature of the Tidyverse is its emphasis on code readability. Functions often have verbal names, arguments prioritize clarity, and the use of the %&gt;% operator suggests a sequential reading of operations. For those coming from traditions where text interpretation and procedure explication are central, this orientation is particularly appealing. The code is presented as a sequence of transformations that can be read almost like a narrative of the analysis (or like a cooking recipe!)2.\nThis does not mean that the Tidyverse replaces R base. In fact, it constantly relies on it. Many Tidyverse functions wrap or reorganize existing functionalities in R base, offering a different interface. Choosing to work with R base, with specific packages, or with the Tidyverse is not a matter of correctness, but of approach. Each option implies adopting certain conventions and foregoing others. It also has to do with knowing the audience for our code: certain packages tend to be more famous in specific fields, and that can prioritize our decision to use them over less known alternatives. Ultimately, it’s about using the language in a way that will facilitate its understanding.\nUnderstanding these differences allows us to move beyond a purely instrumental logic. Using R is not just about knowing which command to execute, but about understanding what conceptual framework we are employing when doing so. R base, packages, and the Tidyverse form layers of the same language, which combine in various ways depending on the research problem, the type of data, and the questions one wants to ask.\nIn the next texts in this series, we will revisit these tools with concrete examples. The idea will not be to learn lists of functions, but to develop criteria for reading code, recognizing styles, and consciously choosing how to work with R in situated research contexts."
  },
  {
    "objectID": "en/posts/r-base-tidyverse.html#footnotes",
    "href": "en/posts/r-base-tidyverse.html#footnotes",
    "title": "R base, packages, and Tidyverse: what we talk about when we use R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAgain, metaphors appear that bring programming language closer to other disciplines. In this case, I’m thinking of Jerry Fodor’s the modular conception of the mind.↩︎\nA clarification is needed here. The famous %&gt;% operator (pipe) was for a long time synonymous with the Tidyverse, although it comes from the specific magrittr package. However, R version 4.1.0, released in May 2021, incorporated a similar operator, |&gt;, meaning that function chaining, like that seen in that charming GIF, is no longer exclusive to the Tidyverse. Strictly speaking, both operators have different functionalities, so massively replacing the %&gt;% operator with |&gt; in our code can lead to errors. The differences might be too technical for someone just starting, but if you’re interested, you can read more here.↩︎"
  },
  {
    "objectID": "en/posts/projects-rstudio.html",
    "href": "en/posts/projects-rstudio.html",
    "title": "Working with projects in RStudio: organizing your work from the start",
    "section": "",
    "text": "When you start using R, it’s common to work with loose files: a script here, a data file there, results saved on the desktop or in unclear folders. This mode of work often functions at first, but it becomes fragile as the analysis grows, as time passes, or when another person needs to understand what was done (or you, in the future!). At that point, a key RStudio tool appears: projects.\nAn RStudio project is a way to organize your work within a main folder. Everything that belongs to a specific analysis or project lives within that space: scripts, data, plots, tables, and documents. When you open a project, RStudio knows where it stands and always works from that location. This avoids one of the most frequent problems when starting out: errors with absolute or relative paths, and files that “cannot be found”.\nFrom a conceptual point of view, working with projects helps to make the work structure explicit. The analysis stops being a succession of dispersed commands and gains a clear framework. Each file serves a purpose, and its location makes sense. Furthermore, the project saves information about the working environment, making it easier to resume analysis after a period without having to reconstruct everything from scratch.\nProjects also promote reproducibility. If everything is within the same folder, it’s easier to move the work to another computer or share it, for example, through a Github repository. There’s no need to rewrite absolute paths or adjust settings every time. RStudio takes care of opening the project and getting everything ready to continue.\n\nHow to create an RStudio project step-by-step\n\nOpen RStudio.\nIn the top menu, click on File and then on New Project….\nRStudio will offer three options. To start, the simplest one is New Directory.\nChoose New Project.\nSpecify the project name and the location where you want the folder to be created.\nClick on Create Project.\n\nRStudio will create a folder with that name and automatically open the project. From that moment on, every time you open that project file, identified by the .Rproj extension, RStudio will work from that folder. You’ll see it in the upper right corner, next to a light blue cube with an “R”:\n\n\n\nWhat changes when working within a project\nOnce the project is created, it’s advisable to adopt some simple practices. Save scripts within the project folder, for example in a subfolder called scripts. Place data in another folder, such as data. Save plots or tables in specific folders. This organization is not mandatory, but it helps make the work more readable.\nAnother important change is the use of relative paths. Within a project, when referring to a file, it is named in relation to the project folder. For example, data/survey.csv. This works as long as the project is open and prevents errors when the analysis is moved.\nRStudio also displays the name of the active project in the upper right corner. This visual detail serves as a constant reminder of the context you are working in. Opening a script without opening the project can cause confusion, so it’s advisable to get used to always starting your work from the .Rproj file.\nFinally: a personal recommendation. Before finishing work or closing the file, try restarting your RStudio session (in the top bar, Session and then Restart R), and try running all the code from scratch. If everything goes well, then your code is clean and ready to be saved. But if you modified something (for example, in the console) that broke the continuity of the code, an error will pop up. And believe me, it’s better to correct it right away than the next day (or months or years later…).\n\n\nProjects as a work habit\nWorking with projects doesn’t require advanced knowledge or change the way you write code. It primarily changes how you organize it. Incorporating this habit from the start saves time, reduces errors, and makes the analysis easier to understand, even for the person who created it.\nIn the next post in this series, we will go a step further and explain how to connect an RStudio project with a version control system. This allows you to track changes, revert to previous states of your work, and collaborate in a more organized way."
  },
  {
    "objectID": "en/posts/integrated-development-environment-ide.html",
    "href": "en/posts/integrated-development-environment-ide.html",
    "title": "Integrated Development Environments (or IDEs, for friends)",
    "section": "",
    "text": "When someone starts programming, one of the first common confusions relates to the working environment. Where does the code “live”? Is it written in a common text file? Is it executed from a console (and what is a console)? Is R the same as RStudio? Do I have to install both things? In what order? These questions are not minor, because they refer to a key distinction: the difference between a programming language and the environment in which that language is used. At this point, the notion of an IDE appears, short for Integrated Development Environment, or integrated development environment.\nAn IDE is a program that brings together several necessary programming tools in one space. Generally speaking, it combines at least four components: a code editor, a console where instructions are executed, tools for exploring files and objects, and aids for writing and reading code. The IDE does not replace the programming language, but rather offers a graphical interface that facilitates its use. R remains R, with its syntax and rules, regardless of the IDE used. However, the work experience changes substantially depending on the chosen environment.\nThere are widely used IDEs across different languages. Visual Studio Code is one of the most popular today and is used for working with multiple languages, from R and Python to JavaScript. Eclipse has a long tradition in Java development. Spyder is common in the Python ecosystem, especially in scientific contexts. In the case of R, the most widespread IDE is RStudio, which was specifically designed to work with this language and with common data analysis practices. In recent years, Positron also appeared, an IDE developed by Posit that reuses many of RStudio’s ideas and articulates them with a more generalist logic, oriented to working with multiple languages. However, in this series, we will focus on RStudio because it remains the most widespread environment in the academic use of R and because its design is deeply aligned with common practices of analysis, teaching, and reproducible writing in this language. And also because it’s what we’re used to :)\nRStudio is organized into an interface that, at first glance, can be overwhelming: panels, tabs, buttons, windows. However, this arrangement responds to a work logic worth understanding. In one panel, you typically find the script editor, where code is written. In another, the console, which allows executing lines or blocks of code and immediately seeing their results. Other panels show the objects available in the session, project files, generated plots, or function documentation. This organization is not merely decorative. It proposes a way of thinking about data work as an activity distributed among writing, execution, exploration, and reading. In this post there is a description of what each of these parts looks like. The important thing is to recognize each unit separately, because eventually the user can rearrange the position of the panels on their screen.\nThe script editor occupies a central place. There, the code is presented as text that can be read, reviewed, and modified. RStudio offers aids such as syntax highlighting, automatic indentation, and autocompletion, although it takes some time to understand these functionalities and incorporate them into daily practice. These features not only reduce technical errors but also facilitate code readability. Colors, indents, and suggestions make structures visible that would otherwise remain hidden in a uniform mass of characters. The IDE, in this sense, acts as a mediator that makes the language more legible. A script is, ultimately, a text.\nWe can think of the script editor as a word processor, like Word or GoogleDocs. The editor will mark with a red cross when something alters R’s syntax (just as word processors underline words with spelling errors). Paying attention to errors is a very effective way to understand how the syntax of a programming language works.\nIn the console, we can execute functions directly, although they will not be saved unless we write them in the script (and this can cause problems if we lose track of our code). Working with the console can be useful when learning, because it enables constant testing, error, and reformulation, but the fact that the code and its results appear in the same place can hinder the clarity of our progress. The IDE does not force a linear path but accompanies back-and-forth processes between hypotheses, code, and results.\nAnother relevant aspect of RStudio is its integration with projects. Working on a project (a post on this is coming!) involves organizing files, data, scripts, and results within a coherent structure. This practice, which may seem excessive at first, becomes fundamental when analyses grow in complexity or when they are resumed after some time. The IDE facilitates this organization and, in doing so, promotes a more reflective and documented way of working. Code ceases to be something ephemeral that is executed once and lost, to become a record of the analytical process. This also fosters reproducibility, a crucial aspect of scientific practice.\nRStudio also includes direct access to documentation, meaning the description and usage guide for functions and packages. When writing a function, it’s possible to quickly consult what it does, what arguments it expects, and what it returns. For example, executing ?summary in the console will yield the specific usage guide for that function. This proximity to help reinforces the idea that programming involves reading as much as writing. Functions are not used blindly; instead, they are interpreted, compared, and chosen based on what one wants to do with the data. No one knows everything by heart; instead, we constantly refer to the materials produced by those who created these functions.\nIt is important to emphasize that learning to use an IDE is not a prerequisite for “knowing how to program,” but it is part of the technical literacy that accompanies language learning. The IDE shapes habits, reading modes, and ways of organizing work. In that sense, it is not neutral. RStudio, in particular, is designed for analytical practices typical of academic work: data exploration, reproducible writing, combining code and text, and producing plots and reports.\nThinking of the IDE as a mere technical support can lead to underestimating it. In reality, it functions as a workspace that embodies a certain conception of programming. For those starting with R from the social sciences and humanities, understanding what an IDE is and how it organizes the programming experience helps dismantle the idea that code is opaque or inaccessible. The environment is also read, interpreted, and learned to be used in a situated manner.\nIn the upcoming texts of this series, we will revisit RStudio in greater detail, observing how certain interface decisions interact with concrete analytical practices. Understanding the environment is a key step to start thinking of code as a language one works with, and not just as a tool that is executed."
  },
  {
    "objectID": "en/posts/index.html",
    "href": "en/posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "What is object-oriented programming and why is R considered an object-oriented language?\n\n\nWhat does it mean for a language to be object-oriented? This post introduces the concept of object-oriented programming and explains how R implements this logic through classes, objects, and methods in daily data work.\n\n\n\n\n\nJan 29, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Data Science and Why All the Interest?\n\n\nWhat is data science and where does it come from? This post explores its origin, its link to statistics and big data, and analyzes why more and more people are approaching this field from diverse analytical traditions.\n\n\n\n\n\nJan 28, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n6 Essential Books for Learning Data Science\n\n\nFive books available online for free for an introduction and in-depth study of data science, from fundamentals and communication to programming with R and applied statistics.\n\n\n\n\n\nJan 27, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nGrammar of Graphics\n\n\nWhat do statistical graphics have in common? This post introduces the idea of the grammar of graphics and shows how ggplot2 allows thinking of visualization as a language composed of explicit analytical decisions.\n\n\n\n\n\nJan 26, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio Projects and Version Control: Working Without Getting Lost in Files\n\n\nWorking with loose files and duplicated versions leads to confusion, especially in collaborative projects. This post introduces the use of RStudio projects combined with version control in GitHub and proposes a more organized and reproducible workflow.\n\n\n\n\n\nJan 24, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with R: Installation and First Steps\n\n\nHow to start with R from scratch? This post explains step-by-step how to install R and RStudio, how to install and load the Tidyverse, and what to check to ensure everything is working correctly.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with projects in RStudio: organizing your work from the start\n\n\nWhat does it mean to work with projects in RStudio and why is it advisable to do so from the beginning? This post explains what projects are for and shows step-by-step how to create and use one in practice.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nReproducibility: why it matters and what it has to do with good programming\n\n\nWhat does it mean for an analysis to be reproducible and why does it matter? This post explains the idea of reproducibility in science and shows how good programming practices help support clear, verifiable, and easy-to-resume analyses.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nConsole and Script: Two Ways to Write Code in R\n\n\nConsole and script serve different functions in R. This post clearly explains what each is for, when to use them, and how they complement each other in daily work.\n\n\n\n\n\nJan 21, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR base, packages, and Tidyverse: what we talk about when we use R\n\n\nWhat is R base, and what changes when we use packages? This post explains R’s modular structure, introduces the role of packages, and dedicates a section to the Tidyverse as a set of tools with its own philosophy for working with data.\n\n\n\n\n\nJan 20, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR for the Humanities: Why Learn to Program?\n\n\nWhy learn to program from the social sciences and humanities? This post proposes thinking about R as a language for analysis and writing, shows simple examples of commented code, and presents programming as a situated practice of knowledge production.\n\n\n\n\n\nJan 18, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nIntegrated Development Environments (or IDEs, for friends)\n\n\nWhat is an IDE and why does it matter when starting to program in R? This text introduces the concept of an integrated development environment, explores common IDEs, and focuses on RStudio as a workspace designed for academic analysis. An invitation to understand the environment as a mediator between code, data, and research practices.\n\n\n\n\n\nJan 17, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR: A Language Born to Think with Data\n\n\nWhat does programming have to do with reading, interpreting, and producing knowledge in social sciences and humanities? This text proposes an entry into R from its history and academic uses, showing how its design, its function-based logic, and its package ecosystem interact with familiar analytical practices. More than a technical introduction, it is an invitation to read code as language and to think of programming as a situated research practice.\n\n\n\n\n\nJan 17, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "en/posts/console-script-writing-code.html",
    "href": "en/posts/console-script-writing-code.html",
    "title": "Console and Script: Two Ways to Write Code in R",
    "section": "",
    "text": "When R or RStudio is opened for the first time, the console is usually the starting point. It’s the window where the &gt; symbol appears and where instructions can be written directly. You write a line of code, press Enter, and R responds. That response can be a number, a table, a message, or a plot. The console basically serves to tell R what to do and see the result immediately.\n\nThe console is useful for quick actions. For example, calculating an average, viewing the content of an object, or testing if a function does what we expect. It’s also common to use it for small trials while learning. The problem is that what is written in the console is not saved in an organized way. If R is closed or the session is restarted, that history is lost. Even with the session open, reviewing what was done a while ago can be confusing.\nThe script serves another function. A script is a file where code is written to be saved. In RStudio, it usually has the .R extension and opens in the editor pane (you can go to File, New File, R Script or click on the icon with a green cross). There, you can write many lines of code, add comments, and organize the analysis step by step. Writing in a script does not execute the code automatically. Each line or block is run only when indicated, either with the button that says “Run”, or with Control+Enter.\n\nThis difference is important. The script allows separating two moments: writing and executing. First, the code is written calmly. Then, it is decided what to execute and when. This makes the work more organized and easier to pick up again. If the file is reopened days or weeks later, the code is still there, in the order it was conceived.\nA very common use is to combine both spaces. The console is used to quickly test something. If that code proves useful, it is copied or written directly into the script. In this way, the script becomes the main record of the work, while the console functions as a testing ground.\nRStudio facilitates this way of working. From the script, code can be executed, and the result appears in the console, but the code remains saved in the script file. This dynamic is especially useful when the analysis has multiple steps or when the work needs to be shared with other people.\nIn practical terms, a good initial rule is this: the console serves for testing and exploring; the script serves for saving and organizing. There’s no need to choose one over the other exclusively. The important thing is to understand what each space contributes and to use it consciously.\nLearning to write in scripts from the beginning saves time later on. It allows for easy error correction, repeating analyses without starting from scratch, and better understanding what was done at each stage. For beginners, this distinction often marks a before and after in how they work with R."
  },
  {
    "objectID": "en/index.html",
    "href": "en/index.html",
    "title": "Atelier de código",
    "section": "",
    "text": "A space dedicated to learning data science, with a focus on research, teaching, and reproducible practices."
  },
  {
    "objectID": "en/index.html#what-youll-find-here",
    "href": "en/index.html#what-youll-find-here",
    "title": "Atelier de código",
    "section": "What you’ll find here",
    "text": "What you’ll find here\n\nResources on R and data analysis\nOpen projects and documentation\nTutoring and mentoring\nData analysis"
  },
  {
    "objectID": "en/about.html",
    "href": "en/about.html",
    "title": "Goal",
    "section": "",
    "text": "From Atelier de código, we want to support you on your journey into data analysis. For those ready to dive in, we offer R courses for beginners (and not-so-beginners as well), covering programming fundamentals, data cleaning and organization, statistical analysis, and visualization. For those who already have a foundation but need someone to think things through with, we provide tutoring sessions where we advise you on your analysis. And for those who don't have the time (or the inclination!) to learn programming, we analyze your data and deliver a tailored report."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Objetivo",
    "section": "",
    "text": "Desde Atelier de código queremos acompañarte en tu camino en el análisis de datos. Para quienes quieran poner manos a la obra, dictamos cursos de R para principiantes (y no tan principiantes también), sobre fundamentos de la programación, limpieza y organización de datos, análisis estadísticos y visualización. Para quienes ya tienen una base pero necesitan pensar con alguien más, ofrecemos tutorías donde te asesoramos sobre tu análisis. Y para quienes no tengan tiempo (¡o ganas!) de aprender a programar, analizamos sus datos y proveemos un reporte a medida."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contacto",
    "section": "",
    "text": "Podés escribirnos a hola@atelierdecodigo.com"
  },
  {
    "objectID": "en/contact.html",
    "href": "en/contact.html",
    "title": "Contact",
    "section": "",
    "text": "You can reach us at hola@atelierdecodigo.com"
  },
  {
    "objectID": "en/posts/books-learning-data-science.html",
    "href": "en/posts/books-learning-data-science.html",
    "title": "6 Essential Books for Learning Data Science",
    "section": "",
    "text": "Delving into data science goes beyond learning syntax or executing commands. Reading books that articulate concepts, techniques, and reflections helps to understand the field as a whole. Fortunately, there are texts freely available on the web that cover everything from fundamentals to concrete applications. Below I present five recommended, open-access books. Some are in English, others in Spanish.\n\n1. R for Data Science (Hadley Wickham, Garrett Grolemund, and Mine Çetinkaya-Rundel)\nThis book is the absolute foundation for programming in R in the world of data science. It covers topics such as data cleaning and visualization, among others. It is designed for beginners but with a level of detail that allows for continuous learning. It has its Spanish version here.\n\n\n2. Telling Stories with Data (Rohan Alexander)\nFocused on statistical communication and analysis narrative, this book covers everything from data collection and cleaning to results presentation. It includes code examples and activities that reinforce the understanding of each technique. Its focus on how to translate data into clear conclusions makes it especially useful for those working with interpretive analysis.\n\n\n3. Libro Vivo de Ciencia de Datos (Pablo Casas)\nThis book in Spanish presents an intuitive introduction to data science and machine learning, with a didactic approach. It offers a practical vision of how to think and work with data from initial levels.\n\n\n4. Deep R Programming (Marek Gagolewski)\nAlthough more technical, this free resource offers a deep introduction to the R language from a data science perspective. The book covers data transformations, numerical computation, functional programming, and advanced structures, with practical examples and exercises.\n\n\n5. OpenIntro Statistics (David Diez, Christopher Barr, and Mine Çetinkaya-Rundel)\nAlthough this text is a statistics book, it is essential reading for data science. Statistics is a pillar of data analysis, and this book guides the reader from basic concepts to applied techniques.\n\n\n6. Learning Statistics with R (Danielle Navarro)\nThis book in English compiles the materials from an introductory statistics course that the author taught at the University of Adelaide, with examples in R. It condenses not only the theory but also the practice for conducting real and informed data analysis. Furthermore, Danielle is a very active person in the R community, and her contributions are truly fundamental.\n\n\nHow to Use These Books in Your Learning\nThese texts serve different purposes: some introduce general concepts, others delve into specific tools, and others integrate programming and analysis. An effective reading strategy can combine a more conceptual book with practical materials that include code exercises and real-world cases.\nIf you are just starting, it can be useful to begin with introductory chapters (for example, data science fundamentals and results communication) before moving on to more technical texts or those focused on specific languages like R."
  },
  {
    "objectID": "en/posts/grammar-graphics-ggplot.html",
    "href": "en/posts/grammar-graphics-ggplot.html",
    "title": "Grammar of Graphics",
    "section": "",
    "text": "The grammar of graphics: thinking of visualization as a language\nGraphics hold a central place in data analysis. They are used to explore patterns, communicate results, and support arguments. However, they are often thought of as a final product, something that is “chosen” from a set of available options. The idea of a grammar of graphics proposes a shift: graphics can be understood as constructions composed of parts or layers, organized according to relatively stable rules, comparable to how languages work.\nInstead of asking “what type of chart should I make”, the question becomes “what do I want to convey”. This will allow us to think about what relationships we want to represent and what elements we need to combine to make them visible. Visualization ceases to be decorative and becomes integrated into analytical reasoning.\n\nWhat is understood by the grammar of graphics\nThe concept of the grammar of graphics was developed by Leland Wilkinson in his book The Grammar of Graphics and starts from a simple idea: any statistical graphic can be decomposed into basic components. These include data, variables mapped to visual properties, geometric shapes that represent that data, and scales that translate values into positions, colors, or sizes.\nFrom this approach, a graphic is not an indivisible object, but the result of a series of explicit decisions. Which variable goes on the horizontal axis, which on the vertical, whether values are represented by points, bars, or lines, how observations are grouped. Each of these choices is part of the graphic’s structure and affects its interpretation.\n\n\nThe grammar of graphics in ggplot2\nHadley Wickham revisits this concept in his article A Layered Grammar of Graphics and introduces his ggplot2 package which implements this idea directly. To build a graphic, one starts with a dataset and adds layers, each with a specific function. The code reflects this compositional logic and allows the graphic to be read as a sequence of decisions.\nA minimal example can illustrate this structure:\nggplot(data = datos, aes(x = edad, y = ingreso)) +\n  geom_point()\nIn this snippet, several key components appear. ggplot() defines the dataset and the basic mapping, i.e., which variables are associated with which visual dimensions. geom_point() adds a concrete geometry, in this case points. If we wanted to change the form of representation, we could replace or add geometries without redoing the entire graphic.\nThis way of working favors controlled experimentation. It is possible to modify just one part of the graphic and observe how the result changes. It also facilitates comparing visualizations that share a common structure, which is especially useful in exploratory analyses.\n\n\nVisualizing as part of the analysis\nThinking of visualization as a language implies recognizing that graphics are not neutral. Each graphic emphasizes certain relationships and relegates others to the background. The grammar of graphics forces us to make these choices explicit, both in the code and in the reasoning that accompanies it.\nIn social analysis contexts, this explicitness is relevant. Visualizing distributions, comparing groups, or tracking temporal evolutions involves defining categories, scales, and units of analysis. The grammar of graphics provides a framework for making these decisions visible and for discussing them.\nFurthermore, by working with code, the graphic becomes reproducible and revisable. Others can read how it was constructed, modify it, or adapt it to new questions. Visualization ceases to be a conclusion of the analysis and becomes part of the process.\n\n\nA tool for learning to read graphics\nThe grammar of graphics not only serves to produce visualizations, but also to read them critically. Identifying which variables are being compared, what scales are used, and what geometries are involved allows for better evaluation of someone else’s graphic and understanding what it shows and what it hides.\nFrom this perspective, learning ggplot2 is not just learning a syntax. It is incorporating a way of thinking about visualization as a situated analytical practice, with rules, possibilities, and limits. In the next posts in the series, we will work with concrete examples to see how this grammar comes into play in common data analysis graphics."
  },
  {
    "objectID": "en/posts/install-r-rstudio.html",
    "href": "en/posts/install-r-rstudio.html",
    "title": "Getting Started with R: Installation and First Steps",
    "section": "",
    "text": "Starting with R often raises very specific questions. What to install, in what order, what each thing is for. Before writing a single line of code, it’s worth clarifying this point, because R works with several pieces that combine with each other. The good news is that the installation process is simple and only needs to be done once.\nThe first step is to install R. R is the programming language itself. To do this, go to the official project site CRAN, and choose the installer file that corresponds to your operating system (Windows, macOS, or Linux). By clicking, you will access the specific instructions for each case.\n\n\n\nInstall R\n\n\nTechnically, we could use R directly from the software we just installed, on Windows and macOS. However, it is not a very user-friendly graphical interface, so most people use other environments like RStudio, VSCode, or Positron. If we are just starting, it is preferable to use RStudio, because most tutorials will show images of that environment.\nAs we mentioned in a previous post, RStudio is an independent program that is installed separately. It is a graphical interface (technically, an integrated development environment) that facilitates the interaction between the user and the R programming language. To install it, you have to go to the RStudio site and download the free version. As seen in the image, we can also install R from here, but if we have already installed it from CRAN, there is no need to install it again.\n\n\n\nInstall RStudio.\n\n\nWhen opening RStudio for the first time, it automatically detects the R installation and is ready to use. From that moment on, RStudio becomes the main workspace.\nWith R and RStudio installed, it is now possible to write and execute code. The next usual step is to install packages, which are add-ons that extend R’s capabilities. One of the most used is the Tidyverse, a set of packages designed to work with data in an organized and readable way (you can read more about what packages are here).\nInstalling a package in R is done by typing an instruction in the console. In the case of the Tidyverse, the command is:\n\ninstall.packages(\"tidyverse\")\n\nOnce we write the code, we must execute it (control+Enter or the “Run” icon). This step requires an internet connection and may take a few minutes, because the Tidyverse includes several packages. Many colored messages will appear in the console: this is normal (unless something says “Warning” or “Error”). The installation is done only once. Once installed, to use it in a work session, you have to load it with:\n\nlibrary(tidyverse)\n\nWarning: package 'tibble' was built under R version 4.4.1\n\n\nWarning: package 'purrr' was built under R version 4.4.1\n\n\nWarning: package 'stringr' was built under R version 4.4.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThis difference between installing and loading often causes confusion at first. Installing downloads the package to the computer. Loading makes it available in the current R session. Every time a new session is started and you want to use the Tidyverse, you have to run library(tidyverse) again.\nAfter loading it, R shows some messages in the console indicating which packages were activated. From that moment on, functions like ggplot, mutate, or filter become available. There’s no need to understand them all immediately. The important thing is to know that they are part of the same ecosystem and share a common logic.\nA practical tip for beginners is to verify that everything is working. For example, write a simple line like:\n\nggplot(mtcars, aes(x = mpg, y = wt)) + geom_point()\n\n\n\n\n\n\n\n\nIf a plot appears, the installation was successful. It doesn’t matter if the code is not yet understood. That will be worked on later.\nInstalling R, RStudio, and the Tidyverse marks the beginning of the work. From there, learning R involves familiarizing oneself with the environment, with writing scripts, and with reading code. Having these tools well installed and working avoids many unnecessary problems and allows you to focus on what’s most important: understanding what the code does and how to use it to analyze data.\nIn the next posts of this series, we will break down these pieces in more detail, so that the initial step transforms into a solid working foundation."
  },
  {
    "objectID": "en/posts/object-oriented-programming.html",
    "href": "en/posts/object-oriented-programming.html",
    "title": "What is object-oriented programming and why is R considered an object-oriented language?",
    "section": "",
    "text": "When you start programming, many operations seem like simple instructions executed in sequence: load data, apply a function, get a result. As projects grow, another need emerges: organizing code and data in a way that is easier to understand, reuse, and extend. Object-oriented programming (OOP) arises as a response to this organizational problem.\nThinking in terms of object orientation involves slightly shifting the focus. Instead of concentrating solely on actions, attention is placed on the entities being acted upon and the relationships between data and operations. This way of structuring code is not exclusive to one language but rather a method for modeling problems.\n\nThe Core Idea of Object Orientation\nGenerally speaking, object-oriented programming is based on the concept of an object. An object combines two things: data and the operations that make sense for that data. For instance, a dataset can have associated operations for summarization, plotting, or transformation.\nObjects usually belong to a class, which defines what kind of data they contain and what operations can be applied. Concrete objects are created from a class. This separation allows working with abstractions: there’s no need to know all the internal details to use an object consistently.\nAnother important concept is that of a method, which is a function associated with a specific class. Instead of thinking of a function as existing in isolation, it is understood as an operation applied to a particular type of object.\n\n\nWhy This Logic Is Useful\nObject orientation helps manage complexity. It allows writing code that adapts to different data types without being completely rewritten, facilitates the extension of functionalities, and promotes a certain internal coherence. For those reading the code, it also offers clues about which operations are expected for each type of object.\nThis way of organizing work is especially valuable in languages used for data analysis, where tables, statistical models, plots, and intermediate results coexist. Each of these elements can be thought of as an object with its own behaviors.\n\n\nR as an Object-Oriented Language\nR is an object-oriented language, although it’s not always perceived that way when you start using it. This is because R implements object orientation in a particular way, less explicit than in other languages like Java or Python.\nIn R, almost everything is an object. A vector, a data frame, a statistical model, or a plot are objects with an associated class. That class defines how they behave with certain functions. For example, the summary() function produces different results depending on the type of object it receives. The same function name activates different methods depending on the class of the input object.\nThis mechanism is known as method dispatch. Instead of calling a specific function for each data type, R internally decides which method to use. For data analysts, this reduces cognitive load: the same general functions are used, and the behavior adjusts to the object.\n\n\nObject Systems in R\nR has several object systems. The most well-known are S3 and S4, and more recently R6. S3 is a flexible and informal system, widely used in packages and in everyday use. S4 is stricter and explicitly defines the structure of classes. R6 is more similar to classic object orientation, with mutable objects.\nTo start, it’s not necessary to master these systems in detail. The important thing is to recognize that when working with data frames, models, or plots, you are interacting with objects that respond to specific rules according to their class.\n\n\nReading Code from This Perspective\nUnderstanding that R is an object-oriented language helps to better read code. It allows you to ask what type of object you are working with, what operations are consistent with that object, and why a function behaves in a certain way. This perspective makes analysis more predictable and facilitates learning new packages.\nObject orientation in R does not require writing classes from day one. It often functions as a silent infrastructure that organizes the language. Recognizing its presence helps to move from executing code to interpreting it as part of a broader system."
  },
  {
    "objectID": "en/posts/projects-version-control-github.html",
    "href": "en/posts/projects-version-control-github.html",
    "title": "RStudio Projects and Version Control: Working Without Getting Lost in Files",
    "section": "",
    "text": "Those who start working with data usually do so with loose files. A script called final_analysis.R, then another final_analysis_v2.R, then real_final_analysis.R. As work progresses, copies appear on different devices, versions sent by email, and duplicated folders. If several people are also involved, the situation quickly becomes confusing: it’s not clear which is the most updated file, what changes each person made, or which version was used to obtain a result.\nA common response to this problem is to move everything to the cloud. Services like Google Drive or Dropbox allow files to be available from different locations and devices. This solves part of the problem, because it reduces the circulation of disconnected copies. However, an important question remains open: how to record changes over time, go back if something goes wrong, or understand what was modified between one version and another of the same file.\nThat’s where version control comes in, and particularly platforms like GitHub1. Version control allows you to save the history of a project, record each change in an organized way, and work collaboratively without stepping on each other’s work. GitHub adds a cloud infrastructure that facilitates sharing projects, collaborating, and maintaining a clear reference of which version is current. Instead of exchanging finished files, you work on the same project, with an explicit record of its evolution.\nIn short, the way Git works is as follows: we have a repository (we can think of it as a folder hosted in the cloud) from which we download a copy to our computer. We make changes to that repository, but as long as we don’t do anything else, the version in the cloud (on GitHub) will remain as it was before. Once we finish working or reach a satisfactory result, we “upload” those changes to that repository and the one in the cloud is updated (and both the repository in the cloud and the one we have on our computer will be identical).\nDifferent people can work with the same repository and “upload” their changes, as long as those changes do not conflict. When this happens (and it will happen, comrades, inevitably), Git allows us to know where that conflict occurs, which versions conflicted (“up to version 4 everything was fine, in Pepito’s version 5 everything went wrong”) and gives us the possibility to revert changes to a previous version (or forcibly accept the changes). The good thing is that Git keeps a record of everything, which can get us out of trouble more than once."
  },
  {
    "objectID": "en/posts/projects-version-control-github.html#footnotes",
    "href": "en/posts/projects-version-control-github.html#footnotes",
    "title": "RStudio Projects and Version Control: Working Without Getting Lost in Files",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhile we will talk about GitHub here, strictly speaking, one thing is Git and another is GitHub. Git is the version control system that is installed locally and is responsible for recording changes in files, something like the technology that allows tracking changes. GitHub, GitLab, and similar platforms are services that host Git repositories in the cloud and add tools for sharing, collaborating, and managing projects.↩︎"
  },
  {
    "objectID": "en/posts/r-humanities-learning.html",
    "href": "en/posts/r-humanities-learning.html",
    "title": "R for the Humanities: Why Learn to Program?",
    "section": "",
    "text": "Learning to program is often presented as a technical skill, associated with a technology-focused job market. For those of us who come from the social sciences and humanities, that world can feel alien. Our daily work has a different materiality (texts?) and is shaped by questions about language, interpretation, category construction, and situated knowledge production. However, increasingly, technological tools are emerging that allow these two worlds to be intertwined, and more and more people from linguistics, sociology, or political science are working with code and data science.\nWe often stop to think about what programming brings to those of us who work in these areas, but what can we bring to that world? What new perspectives can we offer on technology? There’s one that seems central to us, which we’ve mentioned several times because it’s at the core of our experience: programming is writing. Beyond the obvious associations between a “natural language” and a “programming language,” we fundamentally believe there’s a textual dimension shared by both texts and scripts. In this context, we propose to view programming not so much as an instrumental skill, but rather as a practice of writing and analysis that dialogues with already familiar concerns.\nProgramming involves writing instructions in a formal language, but also reading, interpreting, and revising them. An script in R is not just a sequence of commands that “works” or “doesn’t work”: it’s a text that condenses analytical decisions, theoretical assumptions, and methodological choices. Where do we start? How much do we focus on descriptive analysis versus inferential analysis? Do we write alone or do we expect someone else to read us? Do we comment on our text?\nJust as we analyze an academic text by asking what concepts it uses, what it leaves out, or how it organizes its argument, code can also be read critically. Learning to program in R, then, opens up the possibility of thinking with data in an explicit and revisable way.\nR is especially interesting for this cross-section because it was born and developed in academia. Its widespread use in statistics, linguistics, sociology, psychology, and education sciences is no coincidence. The logic of the language favors exploratory and reflective work with data, where each analysis step can be recorded. Furthermore, its package ecosystem reflects specific disciplinary debates and traditions, which materialize in functions, arguments, and data structures. Paradoxically, many people see the R vs Python debate as an academia vs. industry debate (mostly by those from industry who have negative biases towards academic work).\nSomething of this is seen in course learning materials: the vast majority focus on instructions on how to perform a specific task, but rarely are there explanations about the intrinsic functioning of the language. In fact, the linguistic aspect of a programming language is rarely highlighted, despite inheriting attributes such as syntax) or semantics. Those of us who come from linguistics and have an ingrained perspective on the formal or combinatorial aspects of structures have an advantage that is not usually mentioned. Rather, the opposite: those from the social sciences and humanities often feel that their way of thinking is different from what is needed to enter the world of technology (we discussed this at #LatinR2024, in Spanish).\nFrom our perspective, learning to program does not mean abandoning practices specific to other areas. On the contrary, it means extending them to a new type of text. Code becomes a space where theory, method, and data are articulated. Tools like RStudio, and practices such as using reproducible scripts or documents in R Markdown, reinforce this idea by integrating code, text, and results into a single medium.\nIn closing this reflection, it’s worth insisting on a central idea: programming is a situated practice. It is learned in specific contexts, to answer concrete questions, with determined disciplinary traditions. Learning R from the humanities and social sciences does not imply simply adopting an alien language, but rather appropriating it, reading it critically, and using it to think about one’s own problems. Programming, in this sense, is another way of writing, analyzing, and producing knowledge."
  },
  {
    "objectID": "en/posts/reproducibility.html",
    "href": "en/posts/reproducibility.html",
    "title": "Reproducibility: why it matters and what it has to do with good programming",
    "section": "",
    "text": "In many research areas, results are not produced all at once. They are built from data, analytical decisions, adjustments, corrections, and backtracking. In this process, a question arises sooner or later: could another person obtain the same results by following the same steps? This possibility is often called reproducibility.\nReproducibility refers to the ability to repeat an analysis and arrive at the same results using the same data and the same procedures. It does not imply that the results are universal or definitive, but rather that the path that led to them is clear and verifiable. In practical terms, a reproducible analysis allows one to understand what was done, how it was done, and in what order.\nLack of reproducibility is rarely due to malicious intent (though sometimes it happens). Rather, it is often associated with common but unsystematic practices: data files modified without a log, analyses partially done in the console, intermediate steps not saved, results copied and pasted into final documents. Over time, even the person who performed the analysis can lose the ability to reconstruct it.\n\n\n\nWhen we look for the culprit as to why our code no longer works just a few months after we wrote it.\n\n\nAt this point, programming plays a central role. Working with code allows for an explicit record of each decision. A script can show how data was loaded, what transformations were applied, what models were fitted, and how results were produced, both tables and graphs. This record does not depend on memory or subsequent explanations. It is written and can be read, either in plain text using an RMarkdown or Quarto file, or in the comments within the code itself.\nGood programming practices reinforce this logic. Writing code in scripts instead of just in the console allows the entire process to be preserved. Using clear names for objects and functions facilitates readability. Adding comments helps understand why a certain decision was made and not another. Organizing work into projects keeps data, code, and results together. All these practices aim at the same thing: that the analysis can be resumed and understood.\nReproducibility also benefits from the separation between raw data and processed data. Maintaining an original version of the data and performing all transformations via code prevents hard-to-detect errors. If something changes in the input data (for example, if you added subjects to your data collection), the analysis can be rerun without needing to manually redo steps.\nAnother key aspect is automation. When results are generated from code, there’s no need to copy values from one place to another. Graphs, tables, and statistics are produced directly from the scripts. This reduces errors and ensures that the results are aligned with the data and the current analytical decisions.\nTools like RStudio facilitate this approach. Working with projects, using scripts, and the ability to integrate code and text into reproducible documents like RMarkdown allow for building analyses that run from beginning to end. The result is more transparent work, both for the person performing it and for the person reading it.\nReproducibility is not an abstract goal or an external requirement. It has very concrete effects on daily work. It saves time when something needs to be corrected, allows analyses to be resumed after weeks or months, and facilitates exchange with other people. Even when the analysis will not be shared publicly, working reproducibly improves the quality of the process.\nGood programming alone does not guarantee reproducibility, but it creates the conditions for it to be possible. Writing legible, organized, and documented code transforms the analysis into an object that can be reviewed, discussed, and improved. In that sense, good programming practices are as much a part of scientific work as formulating questions or interpreting results.\nIn the upcoming posts in this series, we will continue to delve into concrete tools that help sustain this way of working, from code organization to the use of version control."
  },
  {
    "objectID": "en/posts/what-is-data-science.html",
    "href": "en/posts/what-is-data-science.html",
    "title": "What is Data Science and Why All the Interest?",
    "section": "",
    "text": "In recent years, the expression data science has become ubiquitous. It appears in job offers, academic programs, research projects, and public debates. Sometimes it is presented as a new and homogeneous discipline; other times, as a diffuse set of techniques. To understand what it is about, it is useful to place it historically, review its links with statistics and big data, and consider why it is particularly attractive to those coming from analytical traditions linked to the social sciences.\n\nAn origin linked to concrete problems\nData science does not emerge from a single field or at a precise moment. It consolidates from the convergence of existing practices: statistical analysis, programming, database management, and working with large volumes of information. By the mid-20th century, applied statistics already played a central role in scientific research and decision-making. Later, with the expansion of computing and digital storage, it became possible to work with increasingly larger and more complex datasets.\nThe term data science began to circulate more forcefully towards the late nineties and early two thousands, when it became evident that the problems were no longer just about calculating indicators, but about organizing, cleaning, transforming, and interpreting heterogeneous data. Data science thus configures itself as a practical response to a recurring question: how to produce knowledge from data in contexts where the volume, variety, and velocity of information challenge traditional approaches.\n\nData science and statistics\nThe relationship between data science and statistics is close, though not always obvious. Many of data science’s central tools, such as estimation, inference, or modeling, come directly from statistics. However, data science broadens the focus. In addition to analyzing already prepared data, it deals with the entire process: from obtaining information to communicating results.\nIn this sense, programming plays a key role. Not only as a means to execute calculations, but as a way to describe procedures explicitly and reproducibly. Code allows documenting decisions, repeating analyses, and adjusting intermediate steps. Statistics provides the conceptual frameworks for interpreting results, while programming articulates these frameworks with concrete data and complex workflows.\n\n\nThe link with big data\nBig data often appears associated with data science, although they are not synonyms. Big data refers, in general terms, to large or highly complex datasets that require specific infrastructures for their storage and processing. Data science can work with big data, but also with small databases, surveys, administrative records, or textual corpora.\nWhat they share is a common concern: how to transform data into meaningful information. In many cases, the challenge is not the quantity of data, but its quality, structure, and context of production. From this perspective, data science is not defined solely by volume, but by an approach to analysis that integrates technique, interpretation, and decision-making.\n\n\nWhy it sparks interest in the social sciences\nThe growing interest of people trained in social disciplines in data science has several reasons. Firstly, many contemporary research projects work with digital data: online surveys, administrative databases, social networks, textual archives, or interaction logs. These materials require tools that allow for systematic exploration and analysis.\nSecondly, data science proposes a way of working that dialogues well with classic concerns of social analysis. The need to make assumptions explicit, document procedures, and reflect on the categories used finds an ally in the use of code and reproducible workflows. The analysis leaves traces that can be read, discussed, and reviewed.\nFurthermore, data science brings to the forefront questions about the power of data, biases, representativeness, and the social uses of information. These questions are not foreign to the critical traditions of the social sciences. On the contrary, they offer a space where technical tools and conceptual reflection meet.\n\n\nA situated practice\nMore than a closed discipline, data science can be understood as a situated practice. Its tools adapt to specific problems and concrete contexts of research, work, or intervention. Learning data science involves learning to formulate questions, evaluate sources, make methodological decisions, and communicate results responsibly.\nFrom this perspective, programming, analyzing, and visualizing data are not ends in themselves. They are means to construct knowledge in dialogue with theoretical frameworks, substantive questions, and material conditions of production. Data science thus becomes a fertile space for those who seek to articulate technique and reflection, without losing sight of the fact that data are always anchored in social practices."
  },
  {
    "objectID": "lead-magnet.html",
    "href": "lead-magnet.html",
    "title": "Una guía práctica para empezar a analizar y graficar datos cuantitativos en R",
    "section": "",
    "text": "Empezar a trabajar con datos cuantitativos suele generar una mezcla de entusiasmo y desconcierto. Hay números, tablas extensas, variables con nombres poco claros y una pregunta inicial que siempre vuelve: por dónde empezar. Acá te propongo un recorrido completo, pensado como una guía básica, que va desde la carga y exploración de datos hasta la producción de gráficos claros y reutilizables. El objetivo es mostrar un flujo de trabajo coherente, donde cada paso tenga sentido en relación con el anterior.\nLa idea no es agotar todas las posibilidades de R, sino ofrecer un mapa inicial para orientarse. A lo largo del texto vamos a trabajar con datos reales, funciones ampliamente utilizadas y decisiones analíticas habituales en investigaciones sociales y aplicadas."
  },
  {
    "objectID": "lead-magnet.html#footnotes",
    "href": "lead-magnet.html#footnotes",
    "title": "Una guía práctica para empezar a analizar y graficar datos cuantitativos en R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPara cuando tengas más cancha con RStudio, acá podés encontrar más atajos de teclado en RStudio.↩︎"
  },
  {
    "objectID": "posts/entorno-desarrollo-integrado-ide.html",
    "href": "posts/entorno-desarrollo-integrado-ide.html",
    "title": "Los entornos de desarrollo integrado (o IDE, para los amigos)",
    "section": "",
    "text": "Cuando alguien comienza a programar, una de las primeras confusiones habituales tiene que ver con el entorno de trabajo. ¿Dónde “vive” el código? ¿Se escribe en un archivo de texto común? ¿Se ejecuta desde una consola (y qué es una consola)? ¿Es lo mismo R que RStudio? ¿Tengo que instalar las dos cosas? ¿En qué orden? Estas preguntas no son menores, porque remiten a una distinción clave: la diferencia entre un lenguaje de programación y el entorno en el que ese lenguaje se usa. En ese punto aparece la noción de IDE, sigla de Integrated Development Environment, o entorno de desarrollo integrado.\nUn IDE es un programa que reúne en un mismo espacio varias herramientas necesarias para programar. En términos generales, combina al menos cuatro componentes: un editor de código, una consola donde se ejecutan instrucciones, herramientas para explorar archivos y objetos, y ayudas para la escritura y lectura del código. El IDE no reemplaza al lenguaje de programación, sino que ofrece una interfaz gráfica que facilita su uso. R sigue siendo R, con su sintaxis y sus reglas, independientemente del IDE que se utilice. Sin embargo, la experiencia de trabajo cambia de manera sustantiva según el entorno elegido.\nExisten IDEs ampliamente utilizados en distintos lenguajes. Visual Studio Code es uno de los más populares en la actualidad y se usa para trabajar con múltiples lenguajes, desde R y Python hasta JavaScript. Eclipse tiene una larga tradición en el desarrollo en Java. Spyder es frecuente en el ecosistema Python, especialmente en contextos científicos. En el caso de R, el IDE más extendido es RStudio, que fue diseñado específicamente para trabajar con este lenguaje y con las prácticas habituales del análisis de datos. En los últimos años también apareció Positron, un IDE desarrollado por Posit que retoma muchas de las ideas de RStudio y las articula con una lógica más generalista, orientada al trabajo con múltiples lenguajes. Sin embargo, en esta serie nos detendremos en RStudio porque sigue siendo el entorno más extendido en el uso académico de R y porque su diseño está profundamente alineado con prácticas habituales de análisis, enseñanza y escritura reproducible en este lenguaje. Y también porque es al que estamos acostumbradas :)\nRStudio se organiza en una interfaz que, a primera vista, puede resultar abrumadora: paneles, pestañas, botones, ventanas. Sin embargo, esa disposición responde a una lógica de trabajo que vale la pena comprender. En un panel suele encontrarse el editor de scripts, donde se escribe el código. En otro, la consola, que permite ejecutar líneas o bloques de código y ver inmediatamente sus resultados. Otros paneles muestran los objetos disponibles en la sesión, los archivos del proyecto, los gráficos generados o la documentación de las funciones. Esta organización no es decorativa. Propone una forma de pensar el trabajo con datos como una actividad distribuida entre escritura, ejecución, exploración y lectura. En este post hay una descripción sobre cómo se ve cada una de estas partes. Lo importante es reconocer cada una de las unidades de forma separada, porque eventualmente el usuario puede reorganizar el lugar de los paneles en su pantalla.\nEl editor de scripts ocupa un lugar central. Allí el código se presenta como un texto que puede leerse, revisarse y modificarse. RStudio ofrece ayudas como el resaltado de sintaxis, la indentación automática y el autocompletado, aunque lleva algo de tiempo entender estas funcionalidades e incorporarlas a la práctica cotidiana. Estas funciones no solo reducen errores técnicos, sino que facilitan la lectura del código. Colores, sangrías y sugerencias hacen visibles estructuras que, de otro modo, quedarían ocultas en una masa uniforme de caracteres. El IDE, en este sentido, actúa como un mediador que vuelve más legible el lenguaje. Un script es, en definitiva, un texto.\nPodemos pensar el editor de scripts como un procesador de textos, del estilo de Word o GoogleDocs. El editor marcará con una cruz roja cuando haya algo que altere la sintaxis de R (al igual que los procesadores de texto subrayan palabras con errores ortográficos). Atender a los errores es una forma muy eficaz de entender cómo funciona la sintaxis de un lenguaje de programación.\nEn la consola podemos ejecutar funciones de forma directa, aunque no se guardarán a menos que las escribamos en el script (y esto puede traer problemas si perdemos el hilo de nuestro código). Trabajar con la consola puede ser útil cuando se está aprendiendo, porque habilita la prueba, el error y la reformulación constante, pero el hecho de que el código y sus resultados aparezcan en un mismo lugar puede dificultad la claridad de nuestro recorrido. El IDE no obliga a seguir un recorrido lineal, sino que acompaña procesos de ida y vuelta entre hipótesis, código y resultados.\nOtro aspecto relevante de RStudio es su integración con proyectos. Trabajar en un proyecto (¡se viene un post al respecto!) implica organizar archivos, datos, scripts y resultados dentro de una estructura coherente. Esta práctica, que al comienzo puede parecer excesiva, se vuelve fundamental cuando los análisis crecen en complejidad o cuando se retoman después de un tiempo. El IDE facilita esta organización y, al hacerlo, promueve una forma más reflexiva y documentada de trabajar. El código deja de ser algo efímero que se ejecuta una vez y se pierde, para convertirse en un registro del proceso analítico. Esto, además, favorece la reproducibilidad, un aspecto crucial en la práctica científica.\nRStudio también incorpora un acceso directo a la documentación, esto es, a la descripción y guía de uso de las funciones y paquetes. Al escribir una función, es posible consultar rápidamente qué hace, qué argumentos espera y qué devuelve. Por ejemplo, ejecutar ?summary en la consola dará como resultado la guía específica de uso de esa función. Esta cercanía con la ayuda refuerza la idea de que programar implica leer tanto como escribir. Las funciones no se usan a ciegas, sino que se interpretan, se comparan y se eligen en función de lo que se quiere hacer con los datos. Nadie sabe de memoria, sino que constantemente acudimos a los materiales que produjeron quienes crearon estas funciones.\nEs importante subrayar que aprender a usar un IDE no es un requisito previo para “saber programar”, pero sí forma parte de la alfabetización técnica que acompaña al aprendizaje del lenguaje. El IDE configura hábitos, modos de lectura y formas de organizar el trabajo. En ese sentido, no es neutral. RStudio, en particular, está diseñado para prácticas de análisis propias del trabajo académico: exploración de datos, escritura reproducible, combinación de código y texto, producción de gráficos y reportes.\nPensar el IDE como un simple soporte técnico puede llevar a subestimarlo. En realidad, funciona como un espacio de trabajo que materializa una cierta concepción de la programación. Para quienes se inician en R desde las ciencias sociales y humanas, entender qué es un IDE y cómo organiza la experiencia de programar ayuda a desarmar la idea de que el código es algo opaco o inaccesible. El entorno también se lee, se interpreta y se aprende a usar de manera situada.\nEn los próximos textos de esta serie, volveremos sobre RStudio con mayor detalle, observando cómo ciertas decisiones de interfaz dialogan con prácticas concretas de análisis. Comprender el entorno es un paso clave para empezar a pensar el código como un lenguaje con el que se trabaja, y no solo como una herramienta que se ejecuta."
  },
  {
    "objectID": "posts/gramatica-graficos-ggplot.html",
    "href": "posts/gramatica-graficos-ggplot.html",
    "title": "Gramática de gráficos",
    "section": "",
    "text": "La gramática de los gráficos: pensar la visualización como un lenguaje\nLos gráficos ocupan un lugar central en el análisis de datos. Se los usa para explorar patrones, comunicar resultados y sostener argumentos. Sin embargo, muchas veces se los piensa como un producto final, algo que se “elige” entre un conjunto de opciones disponibles. La idea de una gramática de los gráficos propone un desplazamiento: los gráficos se pueden entender como construcciones compuestas por partes o capas, organizadas según reglas relativamente estables, de forma comparable a cómo funcionan los lenguajes.\nEn lugar de preguntar “qué tipo de gráfico hago”, la pregunta pasa a ser “qué quiero transmitir”. Eso nos va a permitir pensar qué relaciones queremos representar y qué elementos necesitamos combinar para hacerlo visible. La visualización deja de ser decorativa y se integra al razonamiento analítico.\n\nQué se entiende por gramática de los gráficos\nEl concepto de gramática de los gráficos fue desarrollado por Leland Wilkinson en su libro The Grammar of Graphics y parte de una idea sencilla: cualquier gráfico estadístico puede descomponerse en componentes básicos. Entre ellos se encuentran los datos, las variables que se mapean a propiedades visuales, las formas geométricas que representan esos datos y las escalas que traducen valores a posiciones, colores o tamaños.\nDesde este enfoque, un gráfico no es un objeto indivisible, sino el resultado de una serie de decisiones explícitas. Qué variable va en el eje horizontal, cuál en el vertical, si los valores se representan con puntos, barras o líneas, cómo se agrupan las observaciones. Cada una de estas elecciones forma parte de la estructura del gráfico y afecta su interpretación.\n\n\nLa gramática de los gráficos en ggplot2\nHadley Wickham retoma este concepto en su artículo A Layered Grammar of Graphicsy presenta su paquete ggplot2 que implementa esta idea de manera directa. Para construir un gráfico, se parte de un conjunto de datos y se van agregando capas, cada una con una función específica. El código refleja esta lógica composicional y permite leer el gráfico como una secuencia de decisiones.\nUn ejemplo mínimo puede ilustrar esta estructura:\nggplot(data = datos, aes(x = edad, y = ingreso)) +\n  geom_point()\nEn este fragmento aparecen varios componentes clave. ggplot() define el conjunto de datos y el mapeo básico, es decir, qué variables se asocian a qué dimensiones visuales. geom_point() agrega una geometría concreta, en este caso puntos. Si quisiéramos cambiar la forma de representación, podríamos reemplazar o sumar geometrías sin rehacer todo el gráfico.\nEsta forma de trabajar favorece la experimentación controlada. Es posible modificar una sola parte del gráfico y observar cómo cambia el resultado. También facilita comparar visualizaciones que comparten una estructura común, lo que resulta especialmente útil en análisis exploratorios.\n\n\nVisualizar como parte del análisis\nPensar la visualización como un lenguaje implica reconocer que los gráficos no son neutrales. Cada gráfico enfatiza ciertas relaciones y deja otras en segundo plano. La gramática de los gráficos obliga a explicitar estas elecciones, tanto en el código como en el razonamiento que lo acompaña.\nEn contextos de análisis social, esta explicitación es relevante. Visualizar distribuciones, comparar grupos o seguir evoluciones temporales supone definir categorías, escalas y unidades de análisis. La gramática de los gráficos ofrece un marco para hacer visibles estas decisiones y para discutirlas.\nAdemás, al trabajar con código, el gráfico se vuelve reproducible y revisable. Otras personas pueden leer cómo fue construido, modificarlo o adaptarlo a nuevas preguntas. La visualización deja de ser un cierre del análisis y pasa a formar parte del proceso.\n\n\nUna herramienta para aprender a leer gráficos\nLa gramática de los gráficos no solo sirve para producir visualizaciones, sino también para leerlas críticamente. Identificar qué variables están siendo comparadas, qué escalas se usan y qué geometrías intervienen permite evaluar mejor un gráfico ajeno y entender qué muestra y qué oculta.\nDesde esta perspectiva, aprender ggplot2 no es solo aprender una sintaxis. Es incorporar una manera de pensar la visualización como práctica analítica situada, con reglas, posibilidades y límites. En los próximos posts de la serie vamos a trabajar con ejemplos concretos para ver cómo esta gramática se pone en juego en gráficos habituales del análisis de datos."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "¿Qué es la programación orientada a objetos y por qué R se considera un lenguaje orientado a objetos?\n\n\n¿Qué significa que un lenguaje sea orientado a objetos? Este post introduce la idea de programación orientada a objetos y explica cómo R implementa esta lógica a través de clases, objetos y métodos en el trabajo cotidiano con datos.\n\n\n\n\n\nJan 29, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qué es la ciencia de datos y por qué tanto interés?\n\n\n¿Qué es la ciencia de datos y de dónde viene? Este post recorre su origen, su vínculo con la estadística y el big data, y analiza por qué cada vez más personas se acercan a este campo desde tradiciones analíticas diversas.\n\n\n\n\n\nJan 28, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n6 libros imprescindibles para aprender Ciencia de Datos\n\n\nCinco libros disponibles gratuitamente en línea para introducción y profundización en ciencia de datos, desde fundamentos y comunicación hasta programación con R y estadística aplicada.\n\n\n\n\n\nJan 27, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nGramática de gráficos\n\n\n¿Qué tienen en común los gráficos estadísticos? Este post introduce la idea de la gramática de los gráficos y muestra cómo ggplot2 permite pensar la visualización como un lenguaje compuesto por decisiones analíticas explícitas.\n\n\n\n\n\nJan 26, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nProyectos en RStudio y control de versiones: trabajar sin perderse en archivos\n\n\nTrabajar con archivos sueltos y versiones duplicadas genera confusión, sobre todo en trabajos colaborativos. Este post introduce el uso de proyectos en RStudio combinados con control de versiones en GitHub y propone un flujo de trabajo más ordenado y reproducible.\n\n\n\n\n\nJan 24, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nEmpezar con R: instalación y primeros pasos\n\n\n¿Cómo empezar con R desde cero? Este post explica paso a paso cómo instalar R y RStudio, cómo instalar y cargar el Tidyverse y qué verificar para asegurarse de que todo esté funcionando correctamente.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nTrabajar con proyectos en RStudio: ordenar el trabajo desde el inicio\n\n\n¿Qué significa trabajar con proyectos en RStudio y por qué conviene hacerlo desde el inicio? Este post explica para qué sirven los proyectos y muestra paso a paso cómo crear y usar uno en la práctica.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nReproducibilidad: por qué importa y qué tiene que ver con programar bien\n\n\n¿Qué significa que un análisis sea reproducible y por qué importa? Este post explica la idea de reproducibilidad en ciencia y muestra cómo las buenas prácticas de programación ayudan a sostener análisis claros, verificables y fáciles de retomar.\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nConsola y script: dos formas de escribir código en R\n\n\nConsola y script cumplen funciones distintas en R. Este post explica de forma clara para qué sirve cada uno, cuándo conviene usarlos y cómo se complementan en el trabajo cotidiano.\n\n\n\n\n\nJan 21, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR base, paquetes y Tidyverse: de qué hablamos cuando usamos R\n\n\n¿Qué es R base y qué cambia cuando usamos paquetes? Este post explica la estructura modular de R, introduce el rol de los paquetes y dedica una sección al Tidyverse como conjunto de herramientas con una filosofía propia de trabajo con datos.\n\n\n\n\n\nJan 20, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR para humanidades: ¿Por qué aprender a programar?\n\n\n¿Por qué aprender a programar desde las ciencias sociales y humanas? Este post propone pensar R como un lenguaje de análisis y escritura, muestra ejemplos simples de código comentado y presenta la programación como una práctica situada de producción de conocimiento.\n\n\n\n\n\nJan 18, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nLos entornos de desarrollo integrado (o IDE, para los amigos)\n\n\n¿Qué es un IDE y por qué importa al empezar a programar en R? Este texto introduce la idea de entorno de desarrollo integrado, recorre los IDEs más comunes y se detiene en RStudio como espacio de trabajo pensado para el análisis académico. Una invitación a entender el entorno como mediador entre código, datos y prácticas de investigación.\n\n\n\n\n\nJan 17, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nR: un lenguaje que nació para pensar con datos\n\n\n¿Qué tiene que ver programar con leer, interpretar y producir conocimiento en ciencias sociales y humanas? Este texto propone una entrada a R desde su historia y sus usos académicos, mostrando cómo su diseño, su lógica basada en funciones y su ecosistema de paquetes dialogan con prácticas analíticas familiares. Más que una introducción técnica, es una invitación a leer el código como lenguaje y a pensar la programación como una práctica situada de investigación.\n\n\n\n\n\nJan 17, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/lenguaje-orientado-objetos.html",
    "href": "posts/lenguaje-orientado-objetos.html",
    "title": "¿Qué es la programación orientada a objetos y por qué R se considera un lenguaje orientado a objetos?",
    "section": "",
    "text": "Cuando se empieza a programar, muchas de las operaciones parecen simples instrucciones que se ejecutan en secuencia: cargar datos, aplicar una función, obtener un resultado. A medida que los proyectos crecen, aparece otra necesidad: organizar el código y los datos de forma que sea más fácil de entender, reutilizar y extender. La programación orientada a objetos (POO) surge como una respuesta a ese problema de organización.\nPensar en orientación a objetos implica cambiar ligeramente el foco. En lugar de concentrarse solo en acciones, se pone atención en las entidades sobre las que se actúa y en las relaciones entre datos y operaciones. Esta forma de estructurar el código no es exclusiva de un lenguaje, sino una manera de modelar problemas.\n\nLa idea central de la orientación a objetos\nEn términos generales, la programación orientada a objetos se basa en el concepto de objeto. Un objeto combina dos cosas: datos y las operaciones que tienen sentido para esos datos. Por ejemplo, un conjunto de datos puede tener asociadas operaciones para resumirse, graficarse o transformarse.\nLos objetos suelen pertenecer a una clase, que define qué tipo de datos contienen y qué operaciones se pueden aplicar. A partir de una clase se crean objetos concretos. Esta separación permite trabajar con abstracciones: no hace falta conocer todos los detalles internos para usar un objeto de manera consistente.\nOtro concepto importante es el de método, que es una función asociada a una clase específica. En lugar de pensar que una función existe de forma aislada, se la entiende como una operación que se aplica a un tipo particular de objeto.\n\n\nPor qué esta lógica resulta útil\nLa orientación a objetos ayuda a manejar la complejidad. Permite escribir código que se adapta a distintos tipos de datos sin reescribirse por completo, facilita la extensión de funcionalidades y promueve cierta coherencia interna. Para quien lee el código, también ofrece pistas sobre qué operaciones son esperables para cada tipo de objeto.\nEsta forma de organizar el trabajo es especialmente valiosa en lenguajes usados para análisis de datos, donde conviven tablas, modelos estadísticos, gráficos y resultados intermedios. Cada uno de estos elementos puede pensarse como un objeto con comportamientos propios.\n\n\nR como lenguaje orientado a objetos\nR es un lenguaje orientado a objetos, aunque no siempre se lo perciba de ese modo al comenzar a usarlo. Esto se debe a que R implementa la orientación a objetos de una manera particular, menos explícita que en otros lenguajes como Java o Python.\nEn R, casi todo es un objeto. Un vector, un data frame, un modelo estadístico o un gráfico son objetos con una clase asociada. Esa clase define cómo se comportan frente a ciertas funciones. Por ejemplo, la función summary() produce resultados distintos según el tipo de objeto que recibe. El mismo nombre de función activa métodos diferentes según la clase del objeto de entrada.\nEste mecanismo se conoce como despacho de métodos. En lugar de llamar a una función específica para cada tipo de dato, R decide internamente qué método usar. Para quien analiza datos, esto reduce la carga cognitiva: se usan las mismas funciones generales y el comportamiento se ajusta al objeto.\n\n\nLos sistemas de objetos en R\nR tiene varios sistemas de objetos. Los más conocidos son S3 y S4, y más recientemente R6. S3 es un sistema flexible e informal, muy extendido en paquetes y en el uso cotidiano. S4 es más estricto y define de forma explícita la estructura de las clases. R6 se parece más a la orientación a objetos clásica, con objetos mutables.\nPara empezar, no es necesario dominar estos sistemas en detalle. Lo importante es reconocer que cuando se trabaja con data frames, modelos o gráficos, se está interactuando con objetos que responden a reglas específicas según su clase.\n\n\nLeer código desde esta perspectiva\nEntender que R es un lenguaje orientado a objetos ayuda a leer mejor el código. Permite preguntarse qué tipo de objeto se tiene entre manos, qué operaciones son coherentes con ese objeto y por qué una función se comporta de cierta manera. Esta mirada vuelve más predecible el análisis y facilita el aprendizaje de nuevos paquetes.\nLa orientación a objetos en R no exige escribir clases desde el primer día. Funciona, en muchos casos, como una infraestructura silenciosa que organiza el lenguaje. Reconocer su presencia ayuda a pasar de ejecutar código a interpretarlo como parte de un sistema más amplio."
  },
  {
    "objectID": "posts/proyectos-control-versiones-github.html",
    "href": "posts/proyectos-control-versiones-github.html",
    "title": "Proyectos en RStudio y control de versiones: trabajar sin perderse en archivos",
    "section": "",
    "text": "Quienes empiezan a trabajar con datos suelen hacerlo a partir de archivos sueltos. Un script que se llama analisis_final.R, luego otro analisis_final_v2.R, después analisis_final_ahora_si.R. Cuando el trabajo avanza, aparecen copias en distintos dispositivos, versiones enviadas por mail y carpetas duplicadas. Si además participan varias personas, la situación se vuelve rápidamente confusa: no queda claro cuál es el archivo más actualizado, qué cambios hizo cada quien o qué versión se usó para obtener un resultado.\nUna respuesta habitual a este problema es mover todo a la nube. Servicios como Google Drive o Dropbox permiten que los archivos estén disponibles desde distintos lugares y dispositivos. Esto resuelve parte del inconveniente, porque reduce la circulación de copias desconectadas entre sí. Sin embargo, sigue quedando una pregunta importante abierta: cómo registrar los cambios a lo largo del tiempo, volver atrás si algo sale mal o entender qué se modificó entre una versión y otra de un mismo archivo.\nAhí es donde entra el control de versiones, y en particular plataformas como GitHub1. El control de versiones permite guardar la historia de un proyecto, registrar cada cambio de manera ordenada y trabajar de forma coordinada sin pisarse el trabajo. GitHub agrega a esto una infraestructura en la nube que facilita compartir proyectos, colaborar y mantener una referencia clara de qué versión es la vigente. En lugar de intercambiar archivos terminados, se trabaja sobre un mismo proyecto, con un registro explícito de su evolución.\nEn pocas palabras, el funcionamiento de git es el siguiente: tenemos un repositorio (podemos pensarlo como una carpeta alojada en la nube) de la cual nos descargamos una copia en nuestra computadora. Realizamos cambios a ese repositorio, pero mientras no hagamos nada más, la versión que está en la nube (en Github) va a seguir como antes. Una vez que terminamos de trabajar o llegamos a un resultado satisfactorio, “subimos” esos cambios a ese repositorio y el que estaba en la nube se actualiza (y tanto el repositorio en la nube como el que tenemos en nuestra computadora van a ser idénticos).\nDistintas personas pueden trabajar con un mismo repositorio y “subir” sus cambios, siempre y cuando esos cambios no entren en conflicto. Cuando esto ocurre (y va a ocurrir, camaradas, inevitablemente), git nos permite saber dónde se da ese conflicto, cuáles fueron las versiones que entraron en conflicto (“hasta la versión 4 estaba todo bien, en la 5 de Pepito ya se pudrió todo”) y nos da la posibilidad de retrotraer los cambios hasta una versión previa (o aceptar a la fuerza los cambios). Lo bueno es que git guarda registro de todo, lo cual nos puede sacar de un apuro más de una vez."
  },
  {
    "objectID": "posts/proyectos-control-versiones-github.html#footnotes",
    "href": "posts/proyectos-control-versiones-github.html#footnotes",
    "title": "Proyectos en RStudio y control de versiones: trabajar sin perderse en archivos",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSi bien acá vamos a hablar de Github, en rigor de verdad una cosa es Git y otra cosa es Github. git es el sistema de control de versiones que se instala localmente y se encarga de registrar los cambios en los archivos, algo así como la tecnología que permite el seguimiento de los cambios. GitHub, GitLab y plataformas similares son servicios que alojan repositorios git en la nube y agregan herramientas para compartir, colaborar y gestionar proyectos.↩︎"
  },
  {
    "objectID": "posts/que-es-ciencia-de-datos.html",
    "href": "posts/que-es-ciencia-de-datos.html",
    "title": "¿Qué es la ciencia de datos y por qué tanto interés?",
    "section": "",
    "text": "En los últimos años, la expresión ciencia de datos se volvió omnipresente. Aparece en ofertas laborales, programas académicos, proyectos de investigación y debates públicos. A veces se la presenta como una disciplina nueva y homogénea; otras, como un conjunto difuso de técnicas. Para entender de qué se trata, conviene situarla históricamente, revisar sus vínculos con la estadística y el big data, y pensar por qué resulta especialmente atractiva para quienes vienen de tradiciones analíticas vinculadas a lo social.\n\nUn origen ligado a problemas concretos\nLa ciencia de datos no surge de un solo campo ni en un momento preciso. Se consolida a partir de la convergencia de prácticas que ya existían: el análisis estadístico, la programación, la gestión de bases de datos y el trabajo con grandes volúmenes de información. A mediados del siglo XX, la estadística aplicada ya cumplía un rol central en la investigación científica y en la toma de decisiones. Más adelante, con la expansión de la computación y el almacenamiento digital, comenzó a ser posible trabajar con conjuntos de datos cada vez más grandes y complejos.\nEl término data science empieza a circular con más fuerza hacia fines de los años noventa y principios de los dos mil, cuando se vuelve evidente que los problemas ya no pasan solo por calcular indicadores, sino por organizar, limpiar, transformar e interpretar datos heterogéneos. La ciencia de datos se configura así como una respuesta práctica a una pregunta recurrente: cómo producir conocimiento a partir de datos en contextos donde el volumen, la variedad y la velocidad de la información desafían los enfoques tradicionales.\n\nCiencia de datos y estadística\nLa relación entre ciencia de datos y estadística es estrecha, aunque no siempre evidente. Muchas de las herramientas centrales de la ciencia de datos, como la estimación, la inferencia o la modelización, provienen directamente de la estadística. Sin embargo, la ciencia de datos amplía el foco. Además de analizar datos ya preparados, se ocupa de todo el proceso: desde la obtención de la información hasta la comunicación de resultados.\nEn este sentido, programar ocupa un lugar clave. No solo como medio para ejecutar cálculos, sino como forma de describir procedimientos de manera explícita y reproducible. El código permite documentar decisiones, repetir análisis y ajustar pasos intermedios. La estadística aporta los marcos conceptuales para interpretar los resultados, mientras que la programación articula esos marcos con datos concretos y flujos de trabajo complejos.\n\n\nEl vínculo con el big data\nEl big data suele aparecer asociado a la ciencia de datos, aunque no son sinónimos. El big data se refiere, en términos generales, a conjuntos de datos de gran tamaño o alta complejidad, que requieren infraestructuras específicas para su almacenamiento y procesamiento. La ciencia de datos puede trabajar con big data, pero también con bases pequeñas, encuestas, registros administrativos o corpus textuales.\nLo que comparten es una preocupación común: cómo transformar datos en información significativa. En muchos casos, el desafío no está en la cantidad de datos, sino en su calidad, su estructura y su contexto de producción. Desde esta perspectiva, la ciencia de datos no se define solo por el volumen, sino por una forma de abordar el análisis que integra técnica, interpretación y toma de decisiones.\n\n\nPor qué despierta interés en las ciencias sociales\nEl creciente interés de personas formadas en disciplinas sociales por la ciencia de datos tiene varias razones. En primer lugar, muchas investigaciones contemporáneas trabajan con datos digitales: encuestas en línea, bases administrativas, redes sociales, archivos textuales o registros de interacción. Estos materiales requieren herramientas que permitan explorarlos y analizarlos de manera sistemática.\nEn segundo lugar, la ciencia de datos propone un modo de trabajo que dialoga bien con preocupaciones clásicas del análisis social. La necesidad de explicitar supuestos, documentar procedimientos y reflexionar sobre las categorías utilizadas encuentra un aliado en el uso de código y flujos reproducibles. El análisis deja rastros que pueden ser leídos, discutidos y revisados.\nAdemás, la ciencia de datos pone en primer plano preguntas sobre el poder de los datos, los sesgos, la representatividad y los usos sociales de la información. Estas preguntas no son ajenas a las tradiciones críticas de las ciencias sociales. Al contrario, ofrecen un espacio donde herramientas técnicas y reflexión conceptual se encuentran.\n\n\nUna práctica situada\nMás que una disciplina cerrada, la ciencia de datos puede entenderse como una práctica situada. Sus herramientas se adaptan a problemas específicos y a contextos concretos de investigación, trabajo o intervención. Aprender ciencia de datos implica aprender a formular preguntas, a evaluar fuentes, a tomar decisiones metodológicas y a comunicar resultados de forma responsable.\nDesde esta mirada, programar, analizar y visualizar datos no son fines en sí mismos. Son medios para construir conocimiento en diálogo con marcos teóricos, preguntas sustantivas y condiciones materiales de producción. La ciencia de datos se vuelve así un espacio fértil para quienes buscan articular técnica y reflexión, sin perder de vista que los datos siempre están anclados en prácticas sociales."
  },
  {
    "objectID": "posts/r-base-tidyverse.html",
    "href": "posts/r-base-tidyverse.html",
    "title": "R base, paquetes y Tidyverse: de qué hablamos cuando usamos R",
    "section": "",
    "text": "Cuando empezamos a trabajar con R, una de las primeras expresiones que aparecen es “R base”. No, mentira: cuando empezamos a trabajar con R no tenemos idea de lo que estamos haciendo. Copiamos el código de los cursos que estamos haciendo o de los libros o tutoriales que estamos siguiendo. Es posible que esos materiales contengan información sobre la fuente de esas funciones, pero como aprendices nuestra memoria de trabajo está un poco saturada y seguramente no le hayamos prestado atención.\nA medida que vamos incorporando los conceptos y automatizando el ritmo de trabajo, podemos empezar a prestar atención a la teoría. Y vemos que surgen estos conceptos: R base, paquetes, librerías, Tidyverse. Estas palabras circulan con naturalidad en tutoriales, clases y foros, aunque no siempre se explicita qué significan ni cómo se relacionan entre sí. Sin embargo, entender esta arquitectura es clave para poder leer código con mayor autonomía y para tomar decisiones informadas sobre cómo trabajar con datos.\nR base refiere al conjunto de funcionalidades que vienen incluidas cuando se instala R. Incluye el lenguaje propiamente dicho, un conjunto amplio de funciones fundamentales y algunos paquetes básicos que se cargan automáticamente. Operaciones aritméticas, creación de objetos, manejo básico de vectores y data frames, funciones como mean(), sum(), plot() o summary(), forman parte de este núcleo. R base define la gramática mínima del lenguaje y establece las reglas que permiten que todo lo demás funcione.\nTrabajar solo con R base es posible, y de hecho durante muchos años fue la forma estándar de usar R. Sin embargo, ese núcleo está pensado para ser extendido. R fue diseñado desde el inicio como un lenguaje1, capaz de incorporar nuevas funcionalidades sin modificar su estructura central. Esa extensibilidad se materializa a través de los paquetes.\nUn paquete es un conjunto organizado de funciones, datos y documentación que se puede descargar e incorporar a una sesión de R. Cada paquete responde a una necesidad específica: análisis estadístico particular, visualización, manejo de textos, trabajo con encuestas, modelos avanzados o formatos de datos concretos. Técnicamente, instalar un paquete implica descargarlo en la computadora; usarlo implica cargarlo en la sesión activa. Conceptualmente, usar un paquete implica adoptar una forma particular de resolver problemas analíticos. Hay paquetes de todos los gustos y colores: algunos se enfocan en funciones, otros en datos. Dado que hay muchos paquetes distintos que realizan las mismas acciones, en el último tiempo se ha insistido bastante en la importancia de citar los paquetes utilizados en el análisis de datos, con lo cual han surgido, no sin cierta ironía, paquetes que facilitan el citado de los paquetes.\nLos paquetes pueden pensarse como cristalizaciones de prácticas de investigación. Quien desarrolla un paquete toma decisiones sobre qué operaciones facilitar, cómo nombrarlas, qué estructuras de datos privilegiar y qué supuestos dar por sentados. Cuando usamos una función de un paquete, no solo estamos reutilizando código, sino también incorporando una cierta manera de pensar el análisis. Si bien es difícil conocer a fondo el paquete del cual estamos tomando una función, siempre es una buena práctica leer su documentación.\nEn este punto suele aparecer otra fuente de confusión: el término “librería”. En R, librería se usa para referirse al lugar donde están instalados los paquetes en el sistema, y también, por extensión, al acto de cargarlos mediante la función library(). En la práctica cotidiana, hablar de paquetes y librerías suele ser intercambiable, aunque desde un punto de vista técnico no sean exactamente lo mismo. Lo importante es entender que R base se amplía mediante paquetes que se cargan según las necesidades del análisis.\nDentro de este universo de paquetes, hay uno que ocupa un lugar particular: el Tidyverse. El Tidyverse no es un paquete único, sino un conjunto de paquetes diseñados para trabajar de manera coherente entre sí. Incluye herramientas muy utilizadas para la manipulación de datos, la visualización y la importación de archivos, como dplyr, ggplot2, tidyr, readr y stringr, entre otros. Todos comparten una filosofía común y una sintaxis relativamente consistente, que se encuentra en el libro R para ciencia de datos [R for Data Science] de Hadley Wickham y Garrett Gloremund.\nLa propuesta central del Tidyverse es organizar el trabajo con datos a partir de principios claros. Uno de los más conocidos es el concepto de datos “ordenados” (tidy data), donde cada variable ocupa una columna, cada observación una fila y cada tipo de unidad analítica una tabla.\nEste principio, que puede parecer puramente técnico, tiene implicancias analíticas importantes, porque fuerza a explicitar qué se considera una variable, qué cuenta como observación y cómo se estructuran los datos. Esto puede cambiar no solamente entre conjuntos de datos, sino también entre análisis y mismo entre funciones. Por ejemplo, una función que haga un análisis estadístico de comparación de grupos puede tomar la variable de agrupación de una sola columna o puede pedir que cada grupo tenga su propia columna.\nOtro rasgo distintivo del Tidyverse es su énfasis en la legibilidad del código. Las funciones suelen tener nombres verbales, los argumentos privilegian la claridad y el uso del operador %&gt;% propone una lectura secuencial de las operaciones. Para quienes vienen de tradiciones donde la interpretación de textos y la explicitación de procedimientos son centrales, esta orientación resulta especialmente atractiva. El código se presenta como una secuencia de transformaciones que puede leerse casi como una narración del análisis (¡o como una receta de cocina!)2.\nEsto no significa que el Tidyverse reemplace a R base. De hecho, se apoya constantemente en él. Muchas funciones del Tidyverse envuelven o reorganizan funcionalidades existentes en R base, ofreciendo una interfaz distinta. Elegir trabajar con R base, con paquetes específicos o con el Tidyverse no es una cuestión de corrección, sino de enfoque. Cada opción implica adoptar ciertas convenciones y renunciar a otras. También tiene que ver con conocer a la audiencia de nuestro código: determinados paquetes suelen ser más famosos en determinados ámbitos y eso puede privilegiar nuestra decisión de usarlos frente a otras alternativas menos conocidas. En definitiva, se trata de usar el lenguaje de la forma que facilitará su comprensión.\nEntender estas diferencias permite salir de una lógica puramente instrumental. Usar R no consiste solo en saber qué comando ejecutar, sino en comprender qué marco conceptual estamos utilizando al hacerlo. R base, los paquetes y el Tidyverse forman capas de un mismo lenguaje, que se combinan de maneras diversas según el problema de investigación, el tipo de datos y las preguntas que se quieren formular.\nEn los próximos textos de esta serie volveremos sobre estas herramientas con ejemplos concretos. La idea no será aprender listas de funciones, sino desarrollar criterios para leer código, reconocer estilos y elegir conscientemente cómo trabajar con R en contextos de investigación situados."
  },
  {
    "objectID": "posts/r-base-tidyverse.html#footnotes",
    "href": "posts/r-base-tidyverse.html#footnotes",
    "title": "R base, paquetes y Tidyverse: de qué hablamos cuando usamos R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOtra vez aparecen metáforas que acercan el lenguaje de programación a otras disciplinas. En este caso, pienso en la concepción modular de la mente, de Jerry Fodor.↩︎\nAcá hay que hacer una aclaración. El famoso operador %&gt;% (pipe) durante mucho tiempo fue sinónimo de Tidyverse aunque proviene del paquete específico magrittr. Sin embargo, la versión R 4.1.0 que salió en mayo del 2021 incorporó un operador similar, |&gt;, con lo cual la concatenación de funciones como la que se ve en ese simpático gif ya no es exclusiva de Tidyverse. En rigor de verdad, ambos operadores tienen funcionamientos distintos, por lo cual reemplazar el operador %&gt;% por |&gt; de forma masiva en nuestro código puede dar lugar a errores. Las diferencias pueden ser demasiado técnicas para alguien que recién está empezando, pero si les interesa pueden leer un poco acá.↩︎"
  },
  {
    "objectID": "posts/r-lenguaje-programacion.html",
    "href": "posts/r-lenguaje-programacion.html",
    "title": "R: un lenguaje que nació para pensar con datos",
    "section": "",
    "text": "Cuando desde las ciencias sociales y humanas nos acercamos por primera vez a un lenguaje de programación, suele aparecer una sensación ambigua: curiosidad, interés y, al mismo tiempo, cierta cautela. Programar se asocia con frecuencia a una práctica técnica, distante de la lectura, el análisis discursivo o la reflexión teórica. Sin embargo, podemos elegir un punto de entrada diferente para aprender R. Su historia, sus usos y la comunidad que lo sostiene lo convierten en un lenguaje particularmente cercano a una mirada analítica sobre los datos y sobre las condiciones de producción del conocimiento.\nR se originó en el ámbito de la estadística académica. A comienzos de la década de 1990, Ross Ihaka y Robert Gentleman, estadísticos de la Universidad de Auckland, desarrollaron R como una reimplementación libre del lenguaje S, utilizado desde los años setenta en investigación estadística. Desde ese momento inicial, R fue concebido como una herramienta para explorar datos, ensayar modelos y acompañar procesos de investigación científica. Esta procedencia ayuda a entender muchas de sus características actuales y también las prácticas que se consolidaron en torno a su uso.\nUna de las notas distintivas de R es su orientación al análisis interactivo. El código se ejecuta de manera progresiva y permite un trabajo exploratorio con los datos: probar una operación, observar el resultado, ajustar la instrucción y volver a evaluar. Para quienes están habituados a construir análisis de forma iterativa, a partir de hipótesis provisorias y reformulaciones constantes, este modo de trabajo resulta especialmente familiar. Programar en R suele implicar sostener un proceso de exploración controlada, más que seguir un recorrido completamente predefinido.\nDesde el punto de vista técnico, R se apoya fuertemente en el uso de funciones. La mayor parte de las operaciones se realizan aplicando funciones a objetos (de hecho, R es un lenguaje orientado a objetos, al igual que Python). Una función puede entenderse como una operación formalizada que recibe uno o más argumentos, ejecuta una serie de pasos internos y devuelve un resultado. Calcular un promedio, transformar una variable, ajustar un modelo o producir un gráfico son ejemplos de tareas que se realizan mediante funciones. Leer código en R implica identificar qué funciones aparecen, qué argumentos reciben y qué tipo de objeto generan como salida.\nEste énfasis en las funciones favorece una lectura atenta del código como si se tratara de un texto. Cada llamada a una función presenta una estructura relativamente estable: un nombre, paréntesis y argumentos que pueden estar explícitamente nombrados o quedar implícitos mediante valores por defecto. Para quienes tienen experiencia en el análisis de textos, esta sintaxis puede abordarse como un sistema de marcas que orienta la interpretación. Comprender por qué una función produce cierto resultado suele requerir detenerse en esos detalles y en los supuestos que la función incorpora.\nCon el tiempo, los usos de R se expandieron de manera considerable. En la actualidad, se utiliza para análisis estadístico, modelado, visualización de datos, análisis de textos, estudios de redes sociales, trabajo con datos espaciales y experimentos en psicología y lingüística, entre muchos otros campos. Esta expansión se explica en gran medida por el sistema de paquetes. Un paquete es un conjunto organizado de funciones, datos y documentación que amplía las capacidades del lenguaje. R funciona así como un entorno en constante crecimiento, alimentado por contribuciones de distintas comunidades académicas. Para las ciencias sociales y humanas, este rasgo resulta especialmente relevante. Muchas de las herramientas disponibles en R fueron desarrolladas por investigadoras e investigadores que trabajan con problemas afines a los nuestros. Los paquetes orientados al análisis de encuestas, textos, corpus lingüísticos o datos longitudinales incorporan decisiones teóricas y metodológicas específicas. Al leer el código que utiliza estos paquetes, también se accede a esas decisiones: cómo se define una unidad de análisis, qué operaciones se consideran pertinentes, qué supuestos se adoptan sobre los datos.\nEn este sentido, R puede pensarse como un lenguaje en el que se inscriben formas particulares de pensar y de investigar. La existencia de clases de objetos, la representación de los modelos como objetos que pueden ser examinados o la construcción de gráficos por capas organizan la relación entre quien analiza y el fenómeno analizado. Aprender R implica aprender a reconocer y a trabajar con esas mediaciones.\nPor esta razón, en una serie dirigida a quienes se inician en la programación desde las ciencias sociales y humanas, resulta productivo presentar R como un lenguaje con historia, convenciones y comunidades de uso. Leer código en R, incluso cuando al principio lleva tiempo y esfuerzo, forma parte de una alfabetización técnica que dialoga con prácticas habituales de lectura e interpretación.\nEn los próximos textos de esta serie, iremos introduciendo fragmentos concretos de código. El objetivo será aprender a leerlos, descomponerlos y comprender qué están haciendo y qué están diciendo. Programar en R, desde nuestras disciplinas, implica incorporar una nueva forma de escritura y de producción de conocimiento situado."
  }
]